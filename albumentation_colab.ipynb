{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 문서 이미지 분류 - Albumentations 버전\n\n## 대회 정보\n- **Task**: 문서 이미지 분류 (건강보험증, 여권 등)\n- **Train Data**: ~1,500장 | **Test Data**: ~3,000장\n- **Metric**: Macro F1 Score | **Framework**: PyTorch + Albumentations\n\n## Albumentations 장점\n- 🚀 **더 빠른 속도** (transforms 대비 10-100배)\n- 🎨 **80개 이상 증강 기법**\n- 📄 **문서 특화** (GridDistortion, Perspective 등)\n\n---\n\n## 🎯 추천 모델 (실험 순서)\n\n### 1단계: Baseline ⭐⭐⭐⭐⭐\n```python\nCFG.model_name = 'efficientnet_b0'\nCFG.augmentation_level = 'medium'\n```\n**파라미터**: 5M | **속도**: ~1분/epoch | **용도**: 3가지 증강 레벨 테스트\n\n### 2단계: 성능 향상 ⭐⭐⭐⭐⭐\n```python\nCFG.model_name = 'efficientnet_b1'  # 추천 1순위\n# 또는\nCFG.model_name = 'efficientnet_b2'  # 추천 2순위\n```\n**B1**: 7M, ~1.5분/epoch, B0 대비 +2~3% 향상  \n**B2**: 9M, ~2분/epoch, B0 대비 +3~5% 향상\n\n### 3단계: 최신 아키텍처 ⭐⭐⭐⭐⭐\n```python\nCFG.model_name = 'convnext_tiny'\n```\n**파라미터**: 28M | **속도**: ~2.5분/epoch | **특징**: 최신(2022), B0 대비 +5~7% 향상\n\n### 4단계: 성능 극대화 ⭐⭐⭐⭐\n```python\nCFG.model_name = 'efficientnet_b3'  # 1순위\nCFG.augmentation_level = 'heavy'    # 큰 모델엔 강한 증강\n# 또는\nCFG.model_name = 'convnext_small'   # 2순위 (최고 성능)\n```\n**B3**: 12M, ~2.5분/epoch, B0 대비 +5~8% 향상  \n**ConvNeXt-Small**: 50M, ~4분/epoch, B0 대비 +7~10% 향상\n\n### 5단계: Transformer (선택) ⭐⭐\n```python\nCFG.model_name = 'vit_base_patch16_224'\nCFG.augmentation_level = 'heavy'  # 필수!\n# 또는\nCFG.model_name = 'swin_base_patch4_window7_224'\nCFG.augmentation_level = 'heavy'  # 필수!\n```\n**ViT**: 86M, ~5분/epoch | **Swin**: 88M, ~5분/epoch  \n**주의**: 1,500장에선 과적합 위험 높음, Heavy 증강 필수, **비추천**\n\n---\n\n## ⚠️ 비추천 모델\n- `resnet50` / `resnet101` - EfficientNet보다 비효율적\n- `mobilenetv3_large_100` - 속도 빠르지만 성능 낮음\n- `vit` / `swin` - 데이터 부족 시 과적합 (10,000장 이상일 때 추천)\n\n---\n\n## 🚀 실험 시나리오\n\n### 시나리오 1: 빠른 실험 (2시간)\n1. B0 + Light → 30분 (F1: 0.75)\n2. B0 + Medium → 30분 (F1: 0.78)\n3. B0 + Heavy → 30분 (F1: 0.81)\n4. B1 + Heavy → 40분 (F1: 0.84)\n\n### 시나리오 2: 균형 실험 (4시간)\nB0(3가지 증강) → B1 → B2 → ConvNeXt-Tiny → 최고 모델 재학습\n\n### 시나리오 3: 최고 성능 (하루)\nB0 증강 최적화 → B1/B2 → ConvNeXt-Tiny → B3+Heavy → ConvNeXt-Small → 앙상블\n\n---\n\n## 💡 증강 레벨 가이드\n\n| 레벨 | 언제 사용? | 특징 |\n|------|-----------|------|\n| **Light** | 데이터 깨끗/충분 | 빠름, 원본 유지 |\n| **Medium** ⭐ | 대부분 경우 (권장) | 균형, 현실적 변형 |\n| **Heavy** | 데이터 부족/과적합 | 최대 일반화 |\n\n**팁**: 작은 모델(B0/B1) → medium, 큰 모델(B3/ConvNeXt/Transformer) → heavy\n\n---\n\n## 🔧 트러블슈팅\n\n### GPU 메모리 부족 (OOM Error)\n**해결 방법 (우선순위 순):**\n1. `CFG.batch_size = 16` (추천, 이미지 사이즈 유지) ⭐\n2. `CFG.batch_size = 8` (더 안전)\n3. Mixed Precision 사용: `torch.cuda.amp.autocast()`\n4. **최후의 수단**: `CFG.img_size = 256` (권장 안 함, 성능 저하)\n\n**⚠️ 주의**: 문서 이미지는 `img_size`를 256 이하로 줄이지 마세요! 글자가 안 보여 분류가 불가능합니다.\n\n### 학습이 너무 느림\n- Early Stopping이 있으므로 자동으로 최적화됨 (~15 epoch)\n- 수동 조정: `CFG.epochs = 20`\n\n### 성능이 plateau (정체)\n- 모델 크기 키우기보다 **증강/하이퍼파라미터 튜닝** 먼저!\n- Learning rate 조정, 증강 레벨 변경 시도"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install timm wandb albumentations -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Albumentations 임포트\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import wandb\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "print(f'Albumentations version: {A.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "source": "# 환경 자동 감지 (Google Colab vs Local)\nimport sys\n\ntry:\n    import google.colab\n    IS_COLAB = True\n    print(\"🌐 Running on Google Colab\")\nexcept:\n    IS_COLAB = False\n    print(\"💻 Running on Local Machine\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시드 고정 (재현성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Google Drive 마운트 (Colab only)\nif IS_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"✓ Google Drive mounted\")\nelse:\n    print(\"✓ Local environment - skipping drive mount\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# WandB 로그인\nif CFG.use_wandb if 'CFG' in dir() else True:\n    if IS_COLAB:\n        wandb.login()  # Colab에서는 매번 로그인 필요\n        print(\"✓ WandB login required on Colab\")\n    else:\n        # 로컬은 이미 로그인되어 있다고 가정\n        print(\"✓ Using local WandB credentials\")\n\nWANDB_PROJECT = \"document-classification\"\nWANDB_ENTITY = None"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "MODEL_IMG_SIZES = {\n    'efficientnet_b0': 384,\n    'efficientnet_b1': 416,\n    'efficientnet_b2': 448,\n    'efficientnet_b3': 512,\n    'convnext_tiny': 384,\n    'convnext_small': 384,\n}\n\nclass CFG:\n    # 환경별 경로 설정\n    if IS_COLAB:\n        data_dir = '/content/drive/MyDrive/deep_learning_IC/data'\n        drive_model_dir = '/content/drive/MyDrive/deep_learning_IC/models'\n        save_to_drive = True\n    else:\n        data_dir = './data'  # 로컬 데이터 경로\n        drive_model_dir = './models'  # 로컬 모델 저장 경로\n        save_to_drive = True  # 로컬에서도 models 폴더에 저장\n    \n    train_dir = f'{data_dir}/train'\n    test_dir = f'{data_dir}/test'\n    train_csv = f'{data_dir}/train.csv'\n    test_csv = f'{data_dir}/test.csv'\n    \n    # 로컬 모델 저장 경로\n    local_model_path = './best_model.pth'  # 현재 디렉토리에 임시 저장\n    \n    # 모델 설정\n    model_name = 'efficientnet_b0'\n    num_classes = 10\n    img_size = MODEL_IMG_SIZES.get(model_name, 384)\n    \n    # 학습 설정\n    epochs = 30\n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-5\n    \n    # Early Stopping\n    early_stopping_patience = 3\n    early_stopping_min_delta = 0.0001\n    \n    # 데이터 분할\n    val_ratio = 0.2\n    \n    # Albumentations 증강 강도 설정\n    augmentation_level = 'medium'\n    \n    # WandB\n    use_wandb = True\n    wandb_project = WANDB_PROJECT\n    wandb_entity = WANDB_ENTITY\n    experiment_name = None\n    experiment_prefix = None\n    \n    # 기타\n    num_workers = 2\n    seed = 42"
  },
  {
   "cell_type": "code",
   "source": "# 로컬 환경에서 필요한 디렉토리 생성\nif not IS_COLAB:\n    os.makedirs(CFG.data_dir, exist_ok=True)\n    os.makedirs(CFG.drive_model_dir, exist_ok=True)\n    print(f\"✓ Local directories ready:\")\n    print(f\"  - Data: {CFG.data_dir}\")\n    print(f\"  - Models: {CFG.drive_model_dir}\")\nelse:\n    print(f\"✓ Colab environment - using drive paths:\")\n    print(f\"  - Data: {CFG.data_dir}\")\n    print(f\"  - Models: {CFG.drive_model_dir}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Albumentations 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbumentationsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Albumentations를 사용하는 데이터셋 클래스\n",
    "    \n",
    "    주의: Albumentations는 numpy 배열을 입력으로 받으므로\n",
    "    PIL Image를 numpy 배열로 변환해야 합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_paths, labels=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        \n",
    "        # Albumentations는 numpy 배열 또는 OpenCV 이미지를 입력으로 받음\n",
    "        # OpenCV로 읽으면 BGR이므로 RGB로 변환 필요\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            # Albumentations는 dict 형태로 반환\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Albumentations 데이터 증강 설정\n",
    "\n",
    "### 문서 이미지에 특화된 증강 기법\n",
    "\n",
    "#### Light (약한 증강)\n",
    "- 깨끗한 문서 이미지에 적합\n",
    "- 기본적인 색상 조정과 약간의 회전만 적용\n",
    "\n",
    "#### Medium (중간 증강) - **권장**\n",
    "- 대부분의 문서 이미지 분류에 적합\n",
    "- 현실적인 변형들을 시뮬레이션\n",
    "- 조명 변화, 그림자, 약간의 왜곡 등\n",
    "\n",
    "#### Heavy (강한 증강)\n",
    "- 데이터가 매우 부족하거나 높은 다양성이 필요한 경우\n",
    "- 강한 왜곡, 노이즈, 컷아웃 등 포함\n",
    "- 과도한 증강은 오히려 성능 저하를 일으킬 수 있으므로 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms(img_size=224, level='medium'):\n",
    "    \"\"\"\n",
    "    문서 이미지 분류에 특화된 Albumentations 학습용 증강\n",
    "    \n",
    "    Args:\n",
    "        img_size: 입력 이미지 크기\n",
    "        level: 증강 강도 ('light', 'medium', 'heavy')\n",
    "    \"\"\"\n",
    "    \n",
    "    if level == 'light':\n",
    "        return A.Compose([\n",
    "            # 기본 리사이즈\n",
    "            A.Resize(img_size, img_size),\n",
    "            \n",
    "            # 약한 회전 (문서가 약간 기울어진 경우)\n",
    "            A.Rotate(limit=5, p=0.5),\n",
    "            \n",
    "            # 기본 색상 조정\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.1,\n",
    "                contrast_limit=0.1,\n",
    "                p=0.5\n",
    "            ),\n",
    "            \n",
    "            # 정규화 및 텐서 변환\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif level == 'medium':\n",
    "        return A.Compose([\n",
    "            # 기본 리사이즈\n",
    "            A.Resize(img_size, img_size),\n",
    "            \n",
    "            # 수평 뒤집기 (일부 문서는 대칭인 경우)\n",
    "            A.HorizontalFlip(p=0.3),\n",
    "            \n",
    "            # 회전 (문서가 기울어진 경우)\n",
    "            A.Rotate(limit=10, border_mode=cv2.BORDER_CONSTANT, value=255, p=0.5),\n",
    "            \n",
    "            # 원근 변환 (문서를 비스듬히 촬영한 경우)\n",
    "            A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "            \n",
    "            # 색상 및 밝기 조정 (조명 변화)\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.2,\n",
    "                    contrast_limit=0.2,\n",
    "                    p=1.0\n",
    "                ),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=10,\n",
    "                    sat_shift_limit=20,\n",
    "                    val_shift_limit=10,\n",
    "                    p=1.0\n",
    "                ),\n",
    "                A.CLAHE(clip_limit=2.0, p=1.0),\n",
    "            ], p=0.5),\n",
    "            \n",
    "            # 그림자 효과 (조명이 불균일한 경우)\n",
    "            A.RandomShadow(p=0.2),\n",
    "            \n",
    "            # 약간의 블러 (초점이 맞지 않은 경우)\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
    "                A.MotionBlur(blur_limit=3, p=1.0),\n",
    "            ], p=0.2),\n",
    "            \n",
    "            # 약한 노이즈\n",
    "            A.GaussNoise(var_limit=(10.0, 30.0), p=0.2),\n",
    "            \n",
    "            # 정규화 및 텐서 변환\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    elif level == 'heavy':\n",
    "        return A.Compose([\n",
    "            # 기본 리사이즈\n",
    "            A.Resize(img_size, img_size),\n",
    "            \n",
    "            # 수평/수직 뒤집기\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            \n",
    "            # 강한 회전\n",
    "            A.Rotate(limit=15, border_mode=cv2.BORDER_CONSTANT, value=255, p=0.7),\n",
    "            \n",
    "            # 강한 원근/왜곡 변환\n",
    "            A.OneOf([\n",
    "                A.Perspective(scale=(0.05, 0.15), p=1.0),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0),\n",
    "            ], p=0.5),\n",
    "            \n",
    "            # 강한 색상 변환\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.3,\n",
    "                    contrast_limit=0.3,\n",
    "                    p=1.0\n",
    "                ),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=20,\n",
    "                    sat_shift_limit=30,\n",
    "                    val_shift_limit=20,\n",
    "                    p=1.0\n",
    "                ),\n",
    "                A.CLAHE(clip_limit=4.0, p=1.0),\n",
    "                A.ColorJitter(p=1.0),\n",
    "            ], p=0.7),\n",
    "            \n",
    "            # 그림자 및 조명 효과\n",
    "            A.RandomShadow(p=0.3),\n",
    "            \n",
    "            # 블러 효과\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                A.MotionBlur(blur_limit=5, p=1.0),\n",
    "                A.MedianBlur(blur_limit=5, p=1.0),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            # 노이즈\n",
    "            A.OneOf([\n",
    "                A.GaussNoise(var_limit=(20.0, 50.0), p=1.0),\n",
    "                A.ISONoise(p=1.0),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            # 컷아웃 (일부 영역 제거)\n",
    "            A.CoarseDropout(\n",
    "                max_holes=8,\n",
    "                max_height=int(img_size * 0.1),\n",
    "                max_width=int(img_size * 0.1),\n",
    "                fill_value=255,\n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # 정규화 및 텐서 변환\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation level: {level}. Use 'light', 'medium', or 'heavy'.\")\n",
    "\n",
    "\n",
    "def get_valid_transforms(img_size=224):\n",
    "    \"\"\"\n",
    "    검증/테스트용 변환 (증강 없음)\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "# Transform 생성\n",
    "train_transform = get_train_transforms(\n",
    "    img_size=CFG.img_size,\n",
    "    level=CFG.augmentation_level\n",
    ")\n",
    "val_transform = get_valid_transforms(img_size=CFG.img_size)\n",
    "\n",
    "print(f\"Augmentation level: {CFG.augmentation_level}\")\n",
    "print(f\"Train transforms: {len(train_transform)} operations\")\n",
    "print(f\"Valid transforms: {len(val_transform)} operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📌 Albumentations 증강 레벨 선택 가이드\n",
    "\n",
    "### 🎯 어떤 레벨을 선택해야 할까요?\n",
    "\n",
    "**CFG 클래스의 `augmentation_level` 파라미터를 변경하면 됩니다!**\n",
    "\n",
    "```python\n",
    "# 섹션 5의 CFG 클래스에서\n",
    "CFG.augmentation_level = 'medium'  # 이 한 줄만 변경하면 됩니다!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 레벨별 특징 및 추천 상황\n",
    "\n",
    "#### 🟢 **Light** - 약한 증강\n",
    "```python\n",
    "CFG.augmentation_level = 'light'\n",
    "```\n",
    "\n",
    "**적용 증강:**\n",
    "- 약한 회전 (±5도)\n",
    "- 기본 밝기/대비 조정\n",
    "\n",
    "**추천 상황:**\n",
    "- ✅ 문서 이미지가 **매우 깨끗하고 품질이 좋은 경우**\n",
    "- ✅ 데이터가 **충분히 많은 경우** (1000장 이상)\n",
    "- ✅ 학습 데이터가 **실제 테스트 환경과 매우 유사한 경우**\n",
    "- ✅ 과도한 증강으로 인해 성능이 저하되는 경우\n",
    "\n",
    "**장점:** 빠른 학습 속도, 원본 데이터의 특성 유지  \n",
    "**단점:** 일반화 성능이 낮을 수 있음\n",
    "\n",
    "---\n",
    "\n",
    "#### 🟡 **Medium** - 중간 증강 ⭐ **권장!**\n",
    "```python\n",
    "CFG.augmentation_level = 'medium'  # 기본값\n",
    "```\n",
    "\n",
    "**적용 증강:**\n",
    "- 수평 뒤집기 (30%)\n",
    "- 회전 (±10도)\n",
    "- 원근 변환 (Perspective)\n",
    "- 밝기/대비/색조 조정\n",
    "- 그림자 효과\n",
    "- 약한 블러 및 노이즈\n",
    "\n",
    "**추천 상황:**\n",
    "- ✅ **대부분의 문서 이미지 분류 작업** (가장 범용적)\n",
    "- ✅ 데이터가 **중간 정도인 경우** (500-2000장)\n",
    "- ✅ 실제 환경에서 **조명이나 각도가 다양한 경우**\n",
    "- ✅ 스캔/촬영 품질이 **일정하지 않은 경우**\n",
    "- ✅ **첫 실험으로 권장!** 이후 성능을 보고 조정\n",
    "\n",
    "**장점:** 성능과 일반화의 균형, 현실적인 변형 시뮬레이션  \n",
    "**단점:** 없음 (가장 안정적)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔴 **Heavy** - 강한 증강\n",
    "```python\n",
    "CFG.augmentation_level = 'heavy'\n",
    "```\n",
    "\n",
    "**적용 증강:**\n",
    "- 수평/수직 뒤집기\n",
    "- 강한 회전 (±15도)\n",
    "- 강한 원근/그리드 왜곡 변환\n",
    "- 강한 색상 변환\n",
    "- 그림자 및 강한 블러\n",
    "- 노이즈 추가\n",
    "- **CoarseDropout** (일부 영역 제거)\n",
    "\n",
    "**추천 상황:**\n",
    "- ✅ 데이터가 **매우 부족한 경우** (500장 미만)\n",
    "- ✅ **과적합(Overfitting)이 심한 경우**\n",
    "- ✅ 테스트 환경이 **학습 환경과 매우 다른 경우**\n",
    "- ✅ 문서 품질이 **다양하고 예측 불가능한 경우**\n",
    "- ⚠️ Medium으로 시도 후 성능이 낮을 때 고려\n",
    "\n",
    "**장점:** 최대 일반화, 강한 정규화 효과  \n",
    "**단점:** 과도한 증강으로 성능 저하 가능, 학습 시간 증가\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 실험 워크플로우 추천\n",
    "\n",
    "#### **단계 1: Medium으로 시작 (Baseline)**\n",
    "```python\n",
    "CFG.augmentation_level = 'medium'\n",
    "```\n",
    "→ 학습 후 성능 확인\n",
    "\n",
    "#### **단계 2: 성능에 따라 조정**\n",
    "\n",
    "**Case A: Train 정확도 >> Val 정확도 (과적합)**\n",
    "```python\n",
    "CFG.augmentation_level = 'heavy'  # 더 강한 증강으로 정규화\n",
    "```\n",
    "\n",
    "**Case B: Train/Val 모두 높지만 Test가 낮음**\n",
    "```python\n",
    "CFG.augmentation_level = 'heavy'  # 더 다양한 변형 학습\n",
    "```\n",
    "\n",
    "**Case C: Train/Val 모두 낮음**\n",
    "```python\n",
    "CFG.augmentation_level = 'light'  # 증강 약화, 모델/하이퍼파라미터 점검\n",
    "```\n",
    "\n",
    "**Case D: 성능이 충분히 좋음**\n",
    "```python\n",
    "# Medium 유지 또는 Light로 미세 조정\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 WandB에서 비교하기\n",
    "\n",
    "**각 레벨별로 실험을 진행하면 자동으로 다른 이름으로 저장됩니다:**\n",
    "\n",
    "```python\n",
    "# Light 실험\n",
    "CFG.augmentation_level = 'light'\n",
    "# → efficientnet_b0_alb_light_001\n",
    "\n",
    "# Medium 실험\n",
    "CFG.augmentation_level = 'medium'\n",
    "# → efficientnet_b0_alb_medium_001\n",
    "\n",
    "# Heavy 실험\n",
    "CFG.augmentation_level = 'heavy'\n",
    "# → efficientnet_b0_alb_heavy_001\n",
    "```\n",
    "\n",
    "**WandB 대시보드에서 세 실험을 선택하고 비교하세요!**\n",
    "\n",
    "---\n",
    "\n",
    "### 🎨 증강 시각화로 확인하기\n",
    "\n",
    "**섹션 9**의 증강 시각화 코드를 실행하면 각 레벨의 증강 결과를 눈으로 확인할 수 있습니다!\n",
    "\n",
    "```python\n",
    "# 데이터 로드 후 실행\n",
    "visualize_augmentations(train_dataset, idx=0, samples=4)\n",
    "```\n",
    "\n",
    "**증강이 너무 강해 보이면** → Light로 변경  \n",
    "**증강이 너무 약해 보이면** → Heavy로 변경\n",
    "\n",
    "---\n",
    "\n",
    "### 💻 빠른 변경 예시\n",
    "\n",
    "섹션 5의 CFG 클래스로 돌아가서 한 줄만 수정:\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    # ... (다른 설정들)\n",
    "    \n",
    "    # 이 한 줄만 바꾸면 됩니다!\n",
    "    augmentation_level = 'medium'  # 'light', 'medium', 'heavy' 중 선택\n",
    "    \n",
    "    # ... (다른 설정들)\n",
    "```\n",
    "\n",
    "그리고 노트북을 처음부터 다시 실행! 🚀\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. 데이터 로드 및 전처리\n\n**주의**: 이 코드는 제공된 데이터셋 구조에 맞게 작성되었습니다.\n\n데이터 구조:\n```\ndata/\n├── train.csv       (ID, target)\n├── meta.csv        (target, class_name)\n├── train/          (이미지 파일들)\n│   ├── image1.jpg\n│   ├── image2.jpg\n│   └── ...\n└── test/           (테스트 이미지 파일들)\n    ├── test1.jpg\n    └── ...\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 데이터 로드 함수 (train.csv + meta.csv 기반)\ndef load_data_from_csv(train_csv_path, meta_csv_path, train_dir):\n    \"\"\"\n    train.csv와 meta.csv를 읽어서 데이터 로드\n\n    Args:\n        train_csv_path: 'train.csv' 경로 (ID, target)\n        meta_csv_path: 'meta.csv' 경로 (target, class_name)\n        train_dir: 학습 이미지 폴더 경로\n\n    Returns:\n        image_paths, labels, class_to_idx\n    \"\"\"\n    # train.csv 읽기 (ID, target)\n    train_df = pd.read_csv(train_csv_path)\n    print(f\"train.csv loaded: {len(train_df)} entries\")\n\n    # meta.csv 읽기 (target, class_name)\n    meta_df = pd.read_csv(meta_csv_path)\n    print(f\"meta.csv loaded: {len(meta_df)} classes\")\n\n    # class_to_idx 매핑 생성 (class_name → target)\n    class_to_idx = dict(zip(meta_df['class_name'], meta_df['target']))\n\n    # idx_to_class 매핑 생성 (target → class_name)\n    idx_to_class = dict(zip(meta_df['target'], meta_df['class_name']))\n\n    # 이미지 경로와 라벨 리스트 생성\n    image_paths = []\n    labels = []\n    missing_count = 0\n\n    for _, row in train_df.iterrows():\n        img_id = row['ID']\n        target = row['target']\n\n        # 이미지 경로 생성 (확장자가 포함되어 있을 수도 있음)\n        img_path = os.path.join(train_dir, img_id)\n\n        # 파일이 실제로 존재하는지 확인\n        if os.path.exists(img_path):\n            image_paths.append(img_path)\n            labels.append(target)\n        else:\n            # 확장자를 시도해보기\n            found = False\n            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n                img_path_with_ext = os.path.join(train_dir, img_id + ext) if not img_id.endswith(ext) else img_path\n                if os.path.exists(img_path_with_ext):\n                    image_paths.append(img_path_with_ext)\n                    labels.append(target)\n                    found = True\n                    break\n\n            if not found:\n                missing_count += 1\n\n    if missing_count > 0:\n        print(f\"Warning: {missing_count} images from train.csv not found in {train_dir}\")\n\n    print(f\"\\nSuccessfully loaded {len(image_paths)} images\")\n    print(f\"Number of classes: {len(class_to_idx)}\")\n    print(f\"\\nClasses:\")\n    for class_name, idx in sorted(class_to_idx.items(), key=lambda x: x[1]):\n        print(f\"  [{idx}] {class_name}\")\n\n    return image_paths, labels, class_to_idx\n\n# 학습 데이터 로드\ntrain_csv_path = './data/train.csv'\nmeta_csv_path = './data/meta.csv'\n\nif os.path.exists(train_csv_path) and os.path.exists(meta_csv_path) and os.path.exists(CFG.train_dir):\n    train_paths, train_labels, class_to_idx = load_data_from_csv(train_csv_path, meta_csv_path, CFG.train_dir)\n\n    # CFG.num_classes 업데이트\n    CFG.num_classes = len(class_to_idx)\nelse:\n    missing_files = []\n    if not os.path.exists(train_csv_path):\n        missing_files.append(train_csv_path)\n    if not os.path.exists(meta_csv_path):\n        missing_files.append(meta_csv_path)\n    if not os.path.exists(CFG.train_dir):\n        missing_files.append(CFG.train_dir)\n\n    print(f\"Error: Missing required files/directories:\")\n    for f in missing_files:\n        print(f\"  - {f}\")\n    print(\"\\nPlease upload your data or modify the paths in CFG.\")"
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\ndef visualize_random_samples(image_paths, labels, class_to_idx, num_samples=5):\n    \"\"\"\n    데이터셋에서 랜덤으로 샘플을 추출하여 시각화\n    \n    Args:\n        image_paths: 이미지 경로 리스트\n        labels: 라벨 리스트\n        class_to_idx: 클래스명-인덱스 매핑 딕셔너리\n        num_samples: 시각화할 샘플 개수 (기본값: 5)\n    \"\"\"\n    # 인덱스-클래스명 매핑\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    \n    # 랜덤 인덱스 선택\n    random_indices = random.sample(range(len(image_paths)), min(num_samples, len(image_paths)))\n    \n    # 플롯 생성\n    fig, axes = plt.subplots(1, len(random_indices), figsize=(4 * len(random_indices), 4))\n    if len(random_indices) == 1:\n        axes = [axes]\n    \n    for idx, img_idx in enumerate(random_indices):\n        # 이미지 로드\n        img_path = image_paths[img_idx]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # 클래스명 가져오기\n        label_idx = labels[img_idx]\n        class_name = idx_to_class[label_idx]\n        \n        # 시각화\n        axes[idx].imshow(image)\n        axes[idx].set_title(f'Class: {class_name}\\n({os.path.basename(img_path)})', fontsize=10)\n        axes[idx].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# 데이터가 로드된 경우 랜덤 샘플 시각화\nif 'train_paths' in locals() and len(train_paths) > 0:\n    print(f\"\\n{'='*60}\")\n    print(\"데이터셋에서 랜덤으로 5개 샘플 추출 (원본 이미지)\")\n    print(f\"{'='*60}\\n\")\n    visualize_random_samples(train_paths, train_labels, class_to_idx, num_samples=5)\n    \n    # 클래스별 분포 출력\n    print(f\"\\n{'='*60}\")\n    print(\"클래스별 이미지 개수:\")\n    print(f\"{'='*60}\")\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    class_counts = {}\n    for label in train_labels:\n        class_name = idx_to_class[label]\n        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n    \n    for class_name in sorted(class_counts.keys()):\n        print(f\"  {class_name}: {class_counts[class_name]:4d} images\")\n    print(f\"{'='*60}\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8-1. 데이터셋 확인 (랜덤 샘플 5개 시각화)\n\n로드한 데이터가 올바른지 확인하기 위해 각 클래스에서 랜덤으로 샘플을 추출하여 확인합니다.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 8-2. 추가 데이터 분석 (EDA)\n\n데이터의 특성을 더 자세히 파악하기 위한 시각화입니다.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\n\ndef visualize_class_distribution(labels, class_to_idx):\n    \"\"\"Visualize the distribution of classes in the dataset\"\"\"\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    class_names = [idx_to_class[label] for label in labels]\n    class_counts = Counter(class_names)\n    \n    classes = list(class_counts.keys())\n    counts = list(class_counts.values())\n    \n    plt.figure(figsize=(12, 6))\n    bars = plt.bar(classes, counts)\n    plt.xlabel('Class')\n    plt.ylabel('Number of Images')\n    plt.title('Class Distribution in Training Dataset')\n    plt.xticks(rotation=45, ha='right')\n    \n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height,\n                f'{int(height)}',\n                ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\nClass distribution:\")\n    for class_name, count in sorted(class_counts.items()):\n        print(f\"{class_name}: {count} images\")\n\ndef analyze_image_resolutions(image_paths, num_samples=None):\n    \"\"\"Analyze and visualize image resolution distribution\"\"\"\n    from PIL import Image\n    \n    if num_samples:\n        sample_paths = np.random.choice(image_paths, min(num_samples, len(image_paths)), replace=False)\n    else:\n        sample_paths = image_paths\n    \n    widths = []\n    heights = []\n    \n    for img_path in sample_paths:\n        try:\n            with Image.open(img_path) as img:\n                w, h = img.size\n                widths.append(w)\n                heights.append(h)\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n    \n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    \n    axes[0].hist(widths, bins=30, edgecolor='black')\n    axes[0].set_xlabel('Width (pixels)')\n    axes[0].set_ylabel('Frequency')\n    axes[0].set_title('Image Width Distribution')\n    axes[0].axvline(np.mean(widths), color='r', linestyle='--', label=f'Mean: {np.mean(widths):.0f}')\n    axes[0].legend()\n    \n    axes[1].hist(heights, bins=30, edgecolor='black')\n    axes[1].set_xlabel('Height (pixels)')\n    axes[1].set_ylabel('Frequency')\n    axes[1].set_title('Image Height Distribution')\n    axes[1].axvline(np.mean(heights), color='r', linestyle='--', label=f'Mean: {np.mean(heights):.0f}')\n    axes[1].legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nResolution Statistics (from {len(widths)} images):\")\n    print(f\"Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.0f}\")\n    print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.0f}\")\n\ndef visualize_class_grid(image_paths, labels, class_to_idx, samples_per_class=3):\n    \"\"\"Visualize random samples from each class in a grid\"\"\"\n    from PIL import Image\n    \n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    \n    class_images = {class_name: [] for class_name in class_to_idx.keys()}\n    for img_path, label in zip(image_paths, labels):\n        class_name = idx_to_class[label]\n        class_images[class_name].append(img_path)\n    \n    num_classes = len(class_to_idx)\n    fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(samples_per_class * 3, num_classes * 3))\n    \n    if num_classes == 1:\n        axes = axes.reshape(1, -1)\n    \n    for idx, (class_name, img_paths) in enumerate(sorted(class_images.items())):\n        sample_paths = np.random.choice(img_paths, min(samples_per_class, len(img_paths)), replace=False)\n        \n        for col, img_path in enumerate(sample_paths):\n            try:\n                img = Image.open(img_path)\n                axes[idx, col].imshow(img)\n                axes[idx, col].axis('off')\n                if col == 0:\n                    axes[idx, col].set_ylabel(class_name, rotation=0, ha='right', va='center', fontsize=12)\n            except Exception as e:\n                print(f\"Error loading {img_path}: {e}\")\n        \n        for col in range(len(sample_paths), samples_per_class):\n            axes[idx, col].axis('off')\n    \n    plt.suptitle('Random Samples from Each Class', fontsize=16, y=0.995)\n    plt.tight_layout()\n    plt.show()\n\nif 'train_paths' in locals() and len(train_paths) > 0:\n    print(\"=\" * 50)\n    print(\"EXPLORATORY DATA ANALYSIS\")\n    print(\"=\" * 50)\n    \n    print(\"\\n1. Class Distribution Analysis\")\n    print(\"-\" * 50)\n    visualize_class_distribution(train_labels, class_to_idx)\n    \n    print(\"\\n2. Image Resolution Analysis\")\n    print(\"-\" * 50)\n    analyze_image_resolutions(train_paths, num_samples=500)\n    \n    print(\"\\n3. Visual Sample Grid\")\n    print(\"-\" * 50)\n    visualize_class_grid(train_paths, train_labels, class_to_idx, samples_per_class=3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold 설정\n",
    "n_splits = 3\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"3-Fold Cross Validation Ensemble Training\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "if 'train_paths' in locals():\n",
    "    train_dataset = AlbumentationsDataset(train_paths, train_labels, train_transform)\n",
    "    val_dataset = AlbumentationsDataset(val_paths, val_labels, val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=CFG.num_workers\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=CFG.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 증강 결과 시각화 (선택사항)\n",
    "\n",
    "증강이 어떻게 적용되는지 확인해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_augmentations(dataset, idx=0, samples=5):\n",
    "    \"\"\"\n",
    "    데이터셋의 증강 결과를 시각화\n",
    "    \n",
    "    Args:\n",
    "        dataset: AlbumentationsDataset 객체\n",
    "        idx: 시각화할 이미지의 인덱스\n",
    "        samples: 생성할 증강 샘플 수\n",
    "    \"\"\"\n",
    "    # 원본 이미지 로드\n",
    "    img_path = dataset.image_paths[idx]\n",
    "    original_image = cv2.imread(img_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 플롯 생성\n",
    "    fig, axes = plt.subplots(1, samples + 1, figsize=(4 * (samples + 1), 4))\n",
    "    \n",
    "    # 원본 이미지\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title('Original', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 증강된 이미지들\n",
    "    for i in range(samples):\n",
    "        augmented = dataset.transform(image=original_image)\n",
    "        aug_image = augmented['image']\n",
    "        \n",
    "        # 텐서를 numpy로 변환하고 정규화 해제\n",
    "        if isinstance(aug_image, torch.Tensor):\n",
    "            aug_image = aug_image.permute(1, 2, 0).numpy()\n",
    "            # 정규화 해제\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            aug_image = std * aug_image + mean\n",
    "            aug_image = np.clip(aug_image, 0, 1)\n",
    "        \n",
    "        axes[i + 1].imshow(aug_image)\n",
    "        axes[i + 1].set_title(f'Augmented {i+1}', fontsize=12)\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 증강 시각화 (데이터가 로드된 경우)\n",
    "if 'train_dataset' in locals() and len(train_dataset) > 0:\n",
    "    print(f\"Visualizing augmentations with level: {CFG.augmentation_level}\")\n",
    "    visualize_augmentations(train_dataset, idx=0, samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. WandB Run 초기화 (학습 시작 전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_experiment_number(project_name, prefix, entity=None):\n",
    "    \"\"\"WandB에서 기존 실험들을 확인하고 다음 번호를 반환\"\"\"\n",
    "    try:\n",
    "        api = wandb.Api()\n",
    "        # 프로젝트의 모든 run 가져오기\n",
    "        if entity:\n",
    "            runs = api.runs(f\"{entity}/{project_name}\")\n",
    "        else:\n",
    "            runs = api.runs(project_name)\n",
    "        \n",
    "        # prefix로 시작하는 run들의 번호 추출\n",
    "        numbers = []\n",
    "        for run in runs:\n",
    "            if run.name.startswith(prefix):\n",
    "                try:\n",
    "                    # 'prefix_123' 형태에서 123 추출\n",
    "                    num = int(run.name.split('_')[-1])\n",
    "                    numbers.append(num)\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # 가장 큰 번호 + 1 반환\n",
    "        next_num = max(numbers) + 1 if numbers else 1\n",
    "        return next_num\n",
    "    except:\n",
    "        # API 접근 실패시 001부터 시작\n",
    "        return 1\n",
    "\n",
    "# WandB Run 초기화\n",
    "if CFG.use_wandb:\n",
    "    # experiment_prefix가 None이면 모델명 사용 (자동)\n",
    "    if CFG.experiment_prefix is None:\n",
    "        actual_prefix = f\"{CFG.model_name}_alb_{CFG.augmentation_level}\"\n",
    "    else:\n",
    "        actual_prefix = CFG.experiment_prefix\n",
    "    \n",
    "    # 실험명 자동 생성\n",
    "    if CFG.experiment_name is None:\n",
    "        exp_num = get_next_experiment_number(\n",
    "            CFG.wandb_project, \n",
    "            actual_prefix,\n",
    "            CFG.wandb_entity\n",
    "        )\n",
    "        CFG.experiment_name = f\"{actual_prefix}_{exp_num:03d}\"\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project=CFG.wandb_project,\n",
    "        entity=CFG.wandb_entity,\n",
    "        name=CFG.experiment_name,\n",
    "        config={\n",
    "            \"model_name\": CFG.model_name,\n",
    "            \"num_classes\": CFG.num_classes,\n",
    "            \"img_size\": CFG.img_size,\n",
    "            \"epochs\": CFG.epochs,\n",
    "            \"batch_size\": CFG.batch_size,\n",
    "            \"learning_rate\": CFG.learning_rate,\n",
    "            \"weight_decay\": CFG.weight_decay,\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"scheduler\": \"CosineAnnealingLR\",\n",
    "            \"val_ratio\": CFG.val_ratio,\n",
    "            \"seed\": CFG.seed,\n",
    "            \"augmentation\": \"albumentations\",\n",
    "            \"augmentation_level\": CFG.augmentation_level,\n",
    "        }\n",
    "    )\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"WandB Run initialized: {run.name}\")\n",
    "    print(f\"WandB URL: {run.url}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    print(\"WandB is disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, pretrained=True):\n",
    "        super(DocumentClassifier, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        \n",
    "        # 모델의 classifier 부분 수정\n",
    "        if 'efficientnet' in model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(in_features, num_classes)\n",
    "        elif 'resnet' in model_name:\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, num_classes)\n",
    "        elif 'vit' in model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = DocumentClassifier(\n",
    "    model_name=CFG.model_name, \n",
    "    num_classes=CFG.num_classes, \n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model: {CFG.model_name}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# WandB에 모델 아키텍처 로깅\n",
    "if CFG.use_wandb:\n",
    "    wandb.watch(model, log='all', log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 손실 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 학습 및 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # 배치별 메트릭 계산\n",
    "        batch_loss = running_loss / (batch_idx + 1)\n",
    "        batch_acc = 100. * correct / total\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': batch_loss,\n",
    "            'acc': batch_acc\n",
    "        })\n",
    "        \n",
    "        # WandB 로깅 (매 배치마다)\n",
    "        if CFG.use_wandb:\n",
    "            wandb.log({\n",
    "                'train/batch_loss': loss.item(),\n",
    "                'train/batch_acc': 100. * predicted.eq(labels).sum().item() / labels.size(0),\n",
    "                'train/step': epoch * len(train_loader) + batch_idx\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    \n",
    "    # Macro F1 Score 계산\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # 클래스별 F1 Score 계산\n",
    "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    # Confusion Matrix 계산\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, macro_f1, per_class_f1, cm, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold 앙상블 학습 시작\n",
    "fold_models = []  # 각 fold의 모델을 저장\n",
    "fold_results = []  # 각 fold의 결과를 저장\n",
    "\n",
    "# 전체 히스토리 저장용\n",
    "all_fold_history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_f1': []\n",
    "}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_paths, train_labels)):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold+1}/{n_splits}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # 현재 fold의 train/val split\n",
    "    fold_train_paths = [train_paths[i] for i in train_idx]\n",
    "    fold_val_paths = [train_paths[i] for i in val_idx]\n",
    "    fold_train_labels = [train_labels[i] for i in train_idx]\n",
    "    fold_val_labels = [train_labels[i] for i in val_idx]\n",
    "    \n",
    "    print(f\"Fold {fold+1} - Train size: {len(fold_train_paths)}\")\n",
    "    print(f\"Fold {fold+1} - Val size: {len(fold_val_paths)}\")\n",
    "    \n",
    "    # 데이터셋 및 데이터로더 생성\n",
    "    fold_train_dataset = AlbumentationDataset(fold_train_paths, fold_train_labels, train_transform)\n",
    "    fold_val_dataset = AlbumentationDataset(fold_val_paths, fold_val_labels, val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        fold_train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        fold_val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers\n",
    "    )\n",
    "    \n",
    "    # 새 모델 생성 (각 fold마다 새로운 모델)\n",
    "    model = DocumentClassifier(\n",
    "        model_name=CFG.model_name,\n",
    "        num_classes=CFG.num_classes,\n",
    "        pretrained=True\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs, eta_min=1e-6)\n",
    "    \n",
    "    # WandB에 모델 아키텍처 로깅 (첫 번째 fold에만)\n",
    "    if CFG.use_wandb and fold == 0:\n",
    "        wandb.watch(model, log='all', log_freq=100)\n",
    "    \n",
    "    # Fold별 학습\n",
    "    best_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_f1': []\n",
    "    }\n",
    "    \n",
    "    # 구글 드라이브 저장 경로 생성\n",
    "    if CFG.save_to_drive:\n",
    "        os.makedirs(CFG.drive_model_dir, exist_ok=True)\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        print(f\"\\nFold {fold+1} - Epoch {epoch+1}/{CFG.epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 학습\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # 검증\n",
    "        val_loss, val_f1, per_class_f1, cm, val_preds, val_labels_batch = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # 스케줄러 업데이트\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # 결과 저장\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Macro F1: {val_f1:.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # WandB 로깅\n",
    "        if CFG.use_wandb:\n",
    "            log_dict = {\n",
    "                'fold': fold + 1,\n",
    "                'epoch': epoch + 1,\n",
    "                f'fold{fold+1}/train_loss': train_loss,\n",
    "                f'fold{fold+1}/train_acc': train_acc,\n",
    "                f'fold{fold+1}/val_loss': val_loss,\n",
    "                f'fold{fold+1}/val_f1': val_f1,\n",
    "                f'fold{fold+1}/learning_rate': current_lr,\n",
    "                f'fold{fold+1}/patience_counter': patience_counter,\n",
    "            }\n",
    "            \n",
    "            # 클래스별 F1 Score\n",
    "            if 'class_to_idx' in locals():\n",
    "                idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "                for idx, f1 in enumerate(per_class_f1):\n",
    "                    class_name = idx_to_class.get(idx, f'class_{idx}')\n",
    "                    log_dict[f'fold{fold+1}/f1_{class_name}'] = f1\n",
    "            \n",
    "            wandb.log(log_dict)\n",
    "        \n",
    "        # Early Stopping 체크 및 베스트 모델 저장\n",
    "        if val_f1 > best_f1 + CFG.early_stopping_min_delta:\n",
    "            best_f1 = val_f1\n",
    "            patience_counter = 0\n",
    "            \n",
    "            checkpoint = {\n",
    "                'fold': fold,\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_f1': best_f1,\n",
    "            }\n",
    "            \n",
    "            # 로컬에 저장 (fold 번호 포함)\n",
    "            local_model_path = f'best_model_alb_{CFG.augmentation_level}_fold{fold+1}.pth'\n",
    "            torch.save(checkpoint, local_model_path)\n",
    "            print(f\"✓ Fold {fold+1} best model saved locally! (F1: {best_f1:.4f})\")\n",
    "            \n",
    "            # 구글 드라이브에 저장\n",
    "            if CFG.save_to_drive:\n",
    "                if CFG.use_wandb and CFG.experiment_name:\n",
    "                    drive_model_path = f\"{CFG.drive_model_dir}/{CFG.experiment_name}_fold{fold+1}_f1_{best_f1:.4f}.pth\"\n",
    "                else:\n",
    "                    drive_model_path = f\"{CFG.drive_model_dir}/best_model_alb_{CFG.augmentation_level}_fold{fold+1}_f1_{best_f1:.4f}.pth\"\n",
    "                \n",
    "                torch.save(checkpoint, drive_model_path)\n",
    "                if IS_COLAB:\n",
    "                    print(f\"✓ Fold {fold+1} best model saved to Google Drive: {drive_model_path}\")\n",
    "                else:\n",
    "                    print(f\"✓ Fold {fold+1} best model saved locally: {drive_model_path}\")\n",
    "            \n",
    "            # WandB에 베스트 모델 저장\n",
    "            if CFG.use_wandb:\n",
    "                artifact = wandb.Artifact(\n",
    "                    name=f'model-fold{fold+1}-{run.id}',\n",
    "                    type='model',\n",
    "                    description=f'Fold {fold+1} best model with F1: {best_f1:.4f}',\n",
    "                    metadata={\n",
    "                        'fold': fold + 1,\n",
    "                        'epoch': epoch + 1,\n",
    "                        'val_f1': val_f1,\n",
    "                        'val_loss': val_loss,\n",
    "                        'augmentation_level': CFG.augmentation_level,\n",
    "                    }\n",
    "                )\n",
    "                artifact.add_file(local_model_path)\n",
    "                wandb.log_artifact(artifact)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"⚠ No improvement. Patience: {patience_counter}/{CFG.early_stopping_patience}\")\n",
    "            \n",
    "            if patience_counter >= CFG.early_stopping_patience:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"Fold {fold+1} - Early Stopping triggered at epoch {epoch+1}\")\n",
    "                print(f\"Fold {fold+1} - Best Validation Macro F1: {best_f1:.4f}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                break\n",
    "    \n",
    "    # Fold 결과 저장\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_f1': best_f1,\n",
    "        'history': history,\n",
    "        'final_epoch': epoch + 1\n",
    "    })\n",
    "    \n",
    "    # 전체 히스토리에 추가\n",
    "    all_fold_history['train_loss'].extend(history['train_loss'])\n",
    "    all_fold_history['train_acc'].extend(history['train_acc'])\n",
    "    all_fold_history['val_loss'].extend(history['val_loss'])\n",
    "    all_fold_history['val_f1'].extend(history['val_f1'])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Fold {fold+1} completed!\")\n",
    "    print(f\"Fold {fold+1} - Best Validation Macro F1: {best_f1:.4f}\")\n",
    "    print(f\"Fold {fold+1} - Total epochs: {epoch+1}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# 전체 학습 완료 후 결과 출력\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"3-Fold Cross Validation Training Completed!\")\n",
    "print(f\"{'='*60}\")\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: Best F1 = {result['best_f1']:.4f} (Epochs: {result['final_epoch']})\")\n",
    "\n",
    "avg_f1 = sum([r['best_f1'] for r in fold_results]) / len(fold_results)\n",
    "print(f\"\\nAverage F1 across folds: {avg_f1:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 최종 모델 경로 출력\n",
    "print(f\"\\n모델 저장 위치:\")\n",
    "for fold in range(n_splits):\n",
    "    print(f\"  - Fold {fold+1} 로컬: best_model_alb_{CFG.augmentation_level}_fold{fold+1}.pth\")\n",
    "if CFG.save_to_drive:\n",
    "    print(f\"  - 드라이브: {CFG.drive_model_dir}/\")\n",
    "\n",
    "# WandB에 최종 메트릭 로깅\n",
    "if CFG.use_wandb:\n",
    "    wandb.log({\n",
    "        'final/avg_f1': avg_f1,\n",
    "        'final/best_fold': max(fold_results, key=lambda x: x['best_f1'])['fold'],\n",
    "        'final/best_f1': max([r['best_f1'] for r in fold_results]),\n",
    "    })\n",
    "    wandb.finish()\n",
    "\n",
    "# history 변수를 all_fold_history로 설정 (이후 시각화를 위해)\n",
    "history = all_fold_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss 그래프\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title(f'Training and Validation Loss (Albumentations {CFG.augmentation_level})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# F1 Score 그래프\n",
    "axes[1].plot(history['val_f1'], label='Val Macro F1', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Macro F1 Score')\n",
    "axes[1].set_title(f'Validation Macro F1 Score (Albumentations {CFG.augmentation_level})')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 💾 실험 결과 백업 (노트북 사본 저장)\n\n학습이 끝난 후 현재 노트북을 **모델명_F1스코어.ipynb** 형식으로 자동 저장합니다.\n\n**저장 예시:**\n- `efficientnet_b0_f1_0.8234.ipynb`\n- `efficientnet_b1_f1_0.8567.ipynb`\n- `convnext_tiny_f1_0.8892.ipynb`\n\n**장점:**\n- 각 실험 결과를 쉽게 비교\n- 나중에 최고 성능 노트북 찾기 쉬움\n- 실험 히스토리 자동 관리"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import shutil\nfrom datetime import datetime\n\ndef save_notebook_with_score(model_name, f1_score, notebook_name='notebook.ipynb', \n                             save_dir='./experiments'):\n    \"\"\"\n    현재 노트북을 모델명과 F1 스코어를 포함한 이름으로 저장\n    \n    Args:\n        model_name: 모델명 (예: 'efficientnet_b0')\n        f1_score: F1 스코어 (예: 0.8234)\n        notebook_name: 현재 노트북 파일명 (Colab: 자동 감지)\n        save_dir: 저장할 디렉토리\n    \n    Returns:\n        저장된 파일 경로\n    \"\"\"\n    import os\n    \n    # Colab에서 현재 노트북 이름 자동 감지\n    try:\n        from google.colab import drive\n        # Colab 환경에서는 ipynb 파일명을 알 수 없으므로 기본값 사용\n        # 수동으로 지정하거나 마운트된 드라이브에서 확인 필요\n        pass\n    except:\n        pass\n    \n    # 저장 디렉토리 생성\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # 타임스탬프 추가\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    \n    # 새 파일명 생성\n    new_filename = f\"{model_name}_f1_{f1_score:.4f}_{timestamp}.ipynb\"\n    save_path = os.path.join(save_dir, new_filename)\n    \n    # 현재 노트북 복사\n    try:\n        # Colab 환경에서는 직접 복사가 어려우므로 드라이브에 저장\n        if os.path.exists(notebook_name):\n            shutil.copy2(notebook_name, save_path)\n            print(f\"✓ 노트북 저장 완료: {save_path}\")\n        else:\n            # Colab에서는 구글 드라이브에 수동 저장 안내\n            print(f\"\\n{'='*70}\")\n            print(\"Colab 환경에서는 다음 방법으로 노트북을 저장하세요:\")\n            print(f\"{'='*70}\")\n            print(f\"1. 상단 메뉴: 파일 → 드라이브에 사본 저장\")\n            print(f\"2. 파일명을 다음과 같이 변경:\")\n            print(f\"   {new_filename}\")\n            print(f\"{'='*70}\\n\")\n            \n            # 구글 드라이브에 자동 저장 (마운트되어 있는 경우)\n            if CFG.save_to_drive and os.path.exists('/content/drive'):\n                drive_notebook_dir = '/content/drive/MyDrive/document_classification/notebooks'\n                os.makedirs(drive_notebook_dir, exist_ok=True)\n                drive_path = os.path.join(drive_notebook_dir, new_filename)\n                \n                print(f\"💡 추천 저장 경로:\")\n                print(f\"   {drive_path}\")\n                print(f\"\\n   → 위 경로에 수동으로 저장하세요!\")\n                \n                return drive_path\n    except Exception as e:\n        print(f\"✗ 저장 실패: {e}\")\n        return None\n    \n    return save_path\n\n\ndef save_experiment_summary(model_name, f1_score, history, config_dict, \n                           save_path='experiment_summary.txt'):\n    \"\"\"\n    실험 결과 요약 텍스트 파일 저장\n    \n    Args:\n        model_name: 모델명\n        f1_score: 최고 F1 스코어\n        history: 학습 히스토리\n        config_dict: 설정 정보 딕셔너리\n        save_path: 저장 경로\n    \"\"\"\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    \n    summary = f\"\"\"\n{'='*70}\n실험 결과 요약\n{'='*70}\n\n실험 일시: {timestamp}\n모델명: {model_name}\n최고 Validation F1: {f1_score:.4f}\n\n{'='*70}\n학습 설정\n{'='*70}\n\"\"\"\n    \n    for key, value in config_dict.items():\n        summary += f\"{key}: {value}\\n\"\n    \n    summary += f\"\"\"\n{'='*70}\n학습 히스토리\n{'='*70}\nEpoch | Train Loss | Val Loss | Val F1\n------+------------+----------+--------\n\"\"\"\n    \n    for i in range(len(history['train_loss'])):\n        summary += f\"{i+1:5d} | {history['train_loss'][i]:10.4f} | {history['val_loss'][i]:8.4f} | {history['val_f1'][i]:6.4f}\\n\"\n    \n    summary += f\"\"\"\n{'='*70}\n최종 결과\n{'='*70}\nBest Validation F1: {f1_score:.4f}\nTotal Epochs: {len(history['train_loss'])}\nFinal Train Loss: {history['train_loss'][-1]:.4f}\nFinal Val Loss: {history['val_loss'][-1]:.4f}\n{'='*70}\n\"\"\"\n    \n    with open(save_path, 'w', encoding='utf-8') as f:\n        f.write(summary)\n    \n    print(f\"✓ 실험 요약 저장: {save_path}\")\n    \n    # 구글 드라이브에도 저장\n    if CFG.save_to_drive and os.path.exists('/content/drive'):\n        drive_summary_dir = '/content/drive/MyDrive/document_classification/summaries'\n        os.makedirs(drive_summary_dir, exist_ok=True)\n        drive_summary_path = os.path.join(drive_summary_dir, \n                                         f\"{model_name}_f1_{f1_score:.4f}_summary.txt\")\n        shutil.copy2(save_path, drive_summary_path)\n        print(f\"✓ 구글 드라이브에도 저장: {drive_summary_path}\")\n\n\n# 학습 완료 후 자동 저장\nif 'best_f1' in locals() and 'history' in locals():\n    print(f\"\\n{'='*70}\")\n    print(\"실험 결과 자동 백업\")\n    print(f\"{'='*70}\\n\")\n    \n    # 1. 실험 요약 텍스트 파일 저장\n    config_dict = {\n        'Model': CFG.model_name,\n        'Image Size': CFG.img_size,\n        'Batch Size': CFG.batch_size,\n        'Learning Rate': CFG.learning_rate,\n        'Epochs': CFG.epochs,\n        'Augmentation': getattr(CFG, 'augmentation_level', 'N/A'),\n    }\n    \n    save_experiment_summary(\n        model_name=CFG.model_name,\n        f1_score=best_f1,\n        history=history,\n        config_dict=config_dict,\n        save_path=f'{CFG.model_name}_f1_{best_f1:.4f}_summary.txt'\n    )\n    \n    # 2. 노트북 사본 저장 안내\n    print(f\"\\n📓 노트북 저장 안내:\")\n    save_notebook_with_score(\n        model_name=CFG.model_name,\n        f1_score=best_f1,\n        notebook_name='current_notebook.ipynb'  # Colab에서는 자동 감지 불가\n    )\n    \n    print(f\"\\n{'='*70}\")\n    print(\"백업 완료! 🎉\")\n    print(f\"{'='*70}\")\nelse:\n    print(\"⚠️ 학습이 아직 완료되지 않았습니다.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. 틀린 이미지 분석 (Error Analysis)\n\n학습이 끝난 후 validation set에서 틀리게 예측한 이미지들을 확인하여 모델의 약점을 파악할 수 있습니다.\n\n**분석 내용:**\n- 가장 확신있게 틀린 이미지 (모델이 확신했는데 틀린 경우)\n- 클래스별 주요 오분류 패턴\n- 낮은 확신도로 맞춘 샘플 (불확실한 경우)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef analyze_misclassified_images(model, val_dataset, val_paths, val_labels, class_to_idx, \n                                 device, num_samples=12, save_path=None):\n    \"\"\"\n    틀린 이미지들을 시각화하여 모델의 약점 분석\n    \n    Args:\n        model: 학습된 모델\n        val_dataset: Validation 데이터셋\n        val_paths: Validation 이미지 경로 리스트\n        val_labels: Validation 라벨 리스트\n        class_to_idx: 클래스명-인덱스 매핑\n        device: 디바이스\n        num_samples: 시각화할 샘플 개수\n        save_path: 이미지 저장 경로 (None이면 저장 안 함)\n    \"\"\"\n    model.eval()\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    \n    # 틀린 이미지 정보 수집\n    misclassified = []\n    \n    with torch.no_grad():\n        for i in range(len(val_dataset)):\n            image, true_label = val_dataset[i]\n            image_tensor = image.unsqueeze(0).to(device)\n            \n            # 예측\n            output = model(image_tensor)\n            _, predicted = output.max(1)\n            pred_label = predicted.item()\n            \n            # 틀린 경우만 저장\n            if pred_label != true_label:\n                # 확률 계산\n                probs = torch.softmax(output, dim=1)[0]\n                confidence = probs[pred_label].item()\n                true_confidence = probs[true_label].item()\n                \n                misclassified.append({\n                    'index': i,\n                    'path': val_paths[i],\n                    'true_label': true_label,\n                    'pred_label': pred_label,\n                    'true_class': idx_to_class[true_label],\n                    'pred_class': idx_to_class[pred_label],\n                    'confidence': confidence,\n                    'true_confidence': true_confidence\n                })\n    \n    # 결과 출력\n    total_samples = len(val_dataset)\n    num_errors = len(misclassified)\n    accuracy = (total_samples - num_errors) / total_samples * 100\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"Validation Set 에러 분석\")\n    print(f\"{'='*70}\")\n    print(f\"전체 샘플: {total_samples}개\")\n    print(f\"틀린 샘플: {num_errors}개\")\n    print(f\"정확도: {accuracy:.2f}%\")\n    print(f\"{'='*70}\\n\")\n    \n    if num_errors == 0:\n        print(\"✓ 완벽! 모든 샘플을 정확히 예측했습니다!\")\n        return\n    \n    # 클래스별 에러 분석\n    class_errors = {}\n    for item in misclassified:\n        true_class = item['true_class']\n        pred_class = item['pred_class']\n        \n        if true_class not in class_errors:\n            class_errors[true_class] = {}\n        \n        if pred_class not in class_errors[true_class]:\n            class_errors[true_class][pred_class] = 0\n        \n        class_errors[true_class][pred_class] += 1\n    \n    print(\"📊 클래스별 주요 오분류:\")\n    print(f\"{'='*70}\")\n    for true_class in sorted(class_errors.keys()):\n        error_pairs = sorted(class_errors[true_class].items(), \n                           key=lambda x: x[1], reverse=True)\n        top_errors = error_pairs[:3]  # 상위 3개만\n        \n        print(f\"\\n{true_class} (실제):\")\n        for pred_class, count in top_errors:\n            print(f\"  → {pred_class} (예측): {count}회\")\n    print(f\"\\n{'='*70}\\n\")\n    \n    # 시각화할 샘플 선택 (confidence가 높은 순서대로)\n    # confidence가 높은데 틀린 경우 = 모델이 확신했는데 틀린 케이스\n    misclassified_sorted = sorted(misclassified, \n                                 key=lambda x: x['confidence'], \n                                 reverse=True)\n    \n    samples_to_show = min(num_samples, len(misclassified_sorted))\n    \n    # 그리드 레이아웃 계산\n    cols = 4\n    rows = (samples_to_show + cols - 1) // cols\n    \n    # 시각화\n    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n    if rows == 1:\n        axes = axes.reshape(1, -1)\n    \n    for idx in range(rows * cols):\n        row = idx // cols\n        col = idx % cols\n        ax = axes[row, col]\n        \n        if idx < samples_to_show:\n            item = misclassified_sorted[idx]\n            \n            # 이미지 로드\n            img = Image.open(item['path']).convert('RGB')\n            \n            # 시각화\n            ax.imshow(img)\n            \n            # 제목 설정 (여러 줄)\n            title = f\"실제: {item['true_class']}\\n\"\n            title += f\"예측: {item['pred_class']}\\n\"\n            title += f\"확신도: {item['confidence']:.1%}\"\n            \n            # 색상 설정 (확신도가 높을수록 빨간색)\n            title_color = 'red' if item['confidence'] > 0.7 else 'orange'\n            \n            ax.set_title(title, fontsize=9, color=title_color, fontweight='bold')\n            ax.axis('off')\n        else:\n            ax.axis('off')\n    \n    plt.suptitle(f'가장 확신있게 틀린 이미지 Top {samples_to_show}', \n                fontsize=16, fontweight='bold', y=0.995)\n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n        print(f\"✓ 분석 결과 저장: {save_path}\")\n    \n    plt.show()\n    \n    # 추가 분석: 낮은 confidence로 맞춘 경우\n    correct_low_conf = []\n    with torch.no_grad():\n        for i in range(len(val_dataset)):\n            image, true_label = val_dataset[i]\n            image_tensor = image.unsqueeze(0).to(device)\n            \n            output = model(image_tensor)\n            probs = torch.softmax(output, dim=1)[0]\n            _, predicted = output.max(1)\n            pred_label = predicted.item()\n            \n            if pred_label == true_label:\n                confidence = probs[pred_label].item()\n                if confidence < 0.6:  # 확신도가 낮은데 맞춘 경우\n                    correct_low_conf.append({\n                        'index': i,\n                        'path': val_paths[i],\n                        'true_label': true_label,\n                        'true_class': idx_to_class[true_label],\n                        'confidence': confidence\n                    })\n    \n    if correct_low_conf:\n        print(f\"\\n{'='*70}\")\n        print(f\"⚠️ 낮은 확신도로 맞춘 샘플: {len(correct_low_conf)}개\")\n        print(f\"{'='*70}\")\n        print(\"모델이 불확실해하는 샘플들입니다. 추가 학습이나 증강이 필요할 수 있습니다.\\n\")\n\n\n# 에러 분석 실행 (베스트 모델 로드 후)\nif 'val_dataset' in locals() and 'val_paths' in locals():\n    print(\"\\n🔍 Validation Set 에러 분석을 시작합니다...\")\n    analyze_misclassified_images(\n        model=model,\n        val_dataset=val_dataset,\n        val_paths=val_paths,\n        val_labels=val_labels,\n        class_to_idx=class_to_idx,\n        device=device,\n        num_samples=12,  # 12개 샘플 표시\n        save_path='error_analysis.png'  # 결과 저장\n    )\nelse:\n    print(\"⚠️ Validation 데이터가 없습니다. 데이터를 먼저 로드해주세요.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 17. 테스트 데이터 추론"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로드\n",
    "def load_test_data(test_dir):\n",
    "    test_paths = []\n",
    "    for img_name in sorted(os.listdir(test_dir)):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            test_paths.append(os.path.join(test_dir, img_name))\n",
    "    return test_paths\n",
    "\n",
    "if os.path.exists(CFG.test_dir):\n",
    "    test_paths = load_test_data(CFG.test_dir)\n",
    "    print(f\"Total test images: {len(test_paths)}\")\n",
    "else:\n",
    "    print(f\"Warning: {CFG.test_dir} does not exist!\")\n",
    "    test_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 및 로더 생성\n",
    "if test_paths:\n",
    "    test_dataset = AlbumentationsDataset(test_paths, labels=None, transform=val_transform)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=CFG.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 예측 (3개 fold 모델 평균)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Ensemble Prediction with 3 Fold Models\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# 모든 fold 모델 로드\n",
    "fold_models = []\n",
    "for fold in range(n_splits):\n",
    "    model_fold = DocumentClassifier(\n",
    "        model_name=CFG.model_name,\n",
    "        num_classes=CFG.num_classes,\n",
    "        pretrained=False\n",
    "    )\n",
    "    checkpoint_path = f\"best_model_alb_{CFG.augmentation_level}_fold{fold+1}.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model_fold.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model_fold = model_fold.to(device)\n",
    "    model_fold.eval()\n",
    "    fold_models.append(model_fold)\n",
    "    print(f\"✓ Loaded fold {fold+1} model (F1: {checkpoint['best_f1']:.4f})\")\n",
    "\n",
    "# 앙상블 예측\n",
    "ensemble_preds = []\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"Ensemble Inference\"):\n",
    "        if isinstance(images, tuple):\n",
    "            images = images[0]\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # 각 fold 모델의 예측을 평균\n",
    "        fold_outputs = []\n",
    "        for model_fold in fold_models:\n",
    "            outputs = model_fold(images)\n",
    "            fold_outputs.append(torch.softmax(outputs, dim=1))\n",
    "        \n",
    "        # 평균 예측\n",
    "        avg_output = torch.stack(fold_outputs).mean(dim=0)\n",
    "        preds = avg_output.argmax(dim=1)\n",
    "        ensemble_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(f\"\\n✓ Ensemble prediction completed for {len(ensemble_preds)} test images\")\n",
    "\n",
    "# predictions 변수를 ensemble_preds로 업데이트\n",
    "predictions = ensemble_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 18. 제출 파일 생성"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성 (형식은 대회 규정에 맞게 수정)\n",
    "if test_paths and predictions:\n",
    "    # 클래스 인덱스를 클래스 이름으로 변환\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'image': [os.path.basename(path) for path in test_paths],\n",
    "        'label': [idx_to_class[pred] for pred in predictions]\n",
    "    })\n",
    "    \n",
    "    submission_filename = f'submission_alb_{CFG.augmentation_level}.csv'\n",
    "    submission.to_csv(submission_filename, index=False)\n",
    "    print(f\"\\nSubmission file saved: {submission_filename}\")\n",
    "    print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 19. 고급 팁 및 추가 개선 아이디어\n\n### 🔬 커스텀 증강 만들기\n\n기본 제공되는 3가지 레벨 외에 직접 커스텀 증강을 만들 수 있습니다:\n\n```python\n# 예시: 문서 스캔 특화 증강\ncustom_transform = A.Compose([\n    A.Resize(CFG.img_size, CFG.img_size),\n    \n    # 스캔 시 발생하는 노이즈\n    A.OneOf([\n        A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n        A.ISONoise(p=1.0),\n    ], p=0.3),\n    \n    # 구겨진 문서 효과\n    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n    \n    # 팩스/복사기 블러\n    A.Blur(blur_limit=3, p=0.2),\n    \n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n```\n\n---\n\n### 🎯 Test Time Augmentation (TTA)\n\n추론 시에도 증강을 적용하여 **앙상블 효과**를 얻을 수 있습니다:\n\n```python\ndef predict_with_tta(model, image, transforms, n_augmentations=5):\n    \"\"\"\n    TTA를 적용한 예측 함수\n    같은 이미지를 여러 번 증강하고 예측을 평균내어 더 안정적인 결과 획득\n    \"\"\"\n    model.eval()\n    predictions = []\n    \n    with torch.no_grad():\n        for _ in range(n_augmentations):\n            augmented = transforms(image=image)\n            img_tensor = augmented['image'].unsqueeze(0).to(device)\n            output = model(img_tensor)\n            predictions.append(output.softmax(dim=1))\n    \n    # 평균 예측\n    avg_prediction = torch.stack(predictions).mean(dim=0)\n    return avg_prediction.argmax(dim=1).item()\n```\n\n**TTA 사용 시 주의사항:**\n- 추론 시간이 n_augmentations배 증가\n- 일반적으로 0.5-2% 성능 향상\n- 최종 제출 시에만 사용 권장\n\n---\n\n### 📈 성능 향상을 위한 추가 아이디어\n\n#### 1. **증강 파라미터 튜닝**\n```python\n# WandB Sweep으로 최적 증강 강도 찾기\nsweep_config = {\n    'method': 'bayes',\n    'parameters': {\n        'augmentation_level': {\n            'values': ['light', 'medium', 'heavy']\n        },\n        'learning_rate': {\n            'min': 1e-5,\n            'max': 1e-3\n        }\n    }\n}\n```\n\n#### 2. **MixUp / CutMix**\n```python\n# Albumentations의 MixUp transform\nA.MixUp(alpha=0.2, p=0.5)\n```\n\n#### 3. **클래스별 맞춤 증강**\n```python\n# 불균형 데이터셋의 경우 소수 클래스에 더 강한 증강 적용\nif label in minority_classes:\n    transform = heavy_transform\nelse:\n    transform = medium_transform\n```\n\n#### 4. **AutoAugment / RandAugment**\n```python\n# 자동으로 최적 증강 정책 학습\nfrom albumentations.pytorch import ToTensorV2\n# Albumentations도 AutoAugment 지원\n```\n\n---\n\n### 🔍 디버깅 팁\n\n**증강이 너무 강해서 성능이 떨어진다면:**\n1. 섹션 9의 시각화로 증강 결과 확인\n2. `p` (확률) 파라미터 조정\n3. 더 약한 레벨로 변경\n\n**학습이 불안정하다면:**\n1. Learning rate 감소\n2. Batch size 증가\n3. 증강 강도 감소\n\n---\n\n### 📚 참고 자료\n\n- [Albumentations 공식 문서](https://albumentations.ai/docs/)\n- [Albumentations 예제 모음](https://albumentations.ai/docs/examples/)\n- [문서 이미지 증강 Best Practices](https://arxiv.org/abs/2106.08322)\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}