{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ - Augraphy ë²„ì „\n",
    "\n",
    "## ëŒ€íšŒ ì •ë³´\n",
    "- **Task**: ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ (ê±´ê°•ë³´í—˜ì¦, ì—¬ê¶Œ ë“±)\n",
    "- **Train Data**: ~1,500ì¥ | **Test Data**: ~3,000ì¥\n",
    "- **Metric**: Macro F1 Score | **Framework**: PyTorch + Augraphy\n",
    "\n",
    "## ğŸ¯ Augraphyë€?\n",
    "\n",
    "**Augraphy**ëŠ” **ë¬¸ì„œ ì´ë¯¸ì§€ ì „ìš© ì¦ê°• ë¼ì´ë¸ŒëŸ¬ë¦¬**ì…ë‹ˆë‹¤!\n",
    "\n",
    "### ğŸ“„ ë¬¸ì„œ íŠ¹í™” ì¦ê°• ê¸°ë²•\n",
    "\n",
    "ì¼ë°˜ ì´ë¯¸ì§€ ì¦ê°•(Albumentations)ê³¼ ë‹¬ë¦¬, **ì‹¤ì œ ë¬¸ì„œì—ì„œ ë°œìƒí•˜ëŠ” í˜„ìƒë“¤**ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤:\n",
    "\n",
    "- ğŸ“„ **ì¢…ì´ ì§ˆê°** (PaperFactory)\n",
    "- ğŸ–¨ï¸ **ì‰í¬ ë²ˆì§** (InkBleed, DirtyDrum)\n",
    "- ğŸ“  **ìŠ¤ìº”/ë³µì‚¬ ë…¸ì´ì¦ˆ** (ScannerNoise, JpegCompression)\n",
    "- ğŸ“‘ **êµ¬ê²¨ì§„ íš¨ê³¼** (PageBorder, Folding)\n",
    "- â˜• **ì–¼ë£©** (WaterMark, SubtleNoise)\n",
    "- ğŸ’¡ **ì¡°ëª… ë¶ˆê· í˜•** (Brightness, LightingGradient)\n",
    "- âœï¸ **í•„ê¸° í”ì ** (Scribbles)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ†š Augraphy vs Albumentations\n",
    "\n",
    "| íŠ¹ì§• | Albumentations | Augraphy |\n",
    "|------|---------------|----------|\n",
    "| **ëŒ€ìƒ** | ì¼ë°˜ ì´ë¯¸ì§€ | ë¬¸ì„œ ì´ë¯¸ì§€ ì „ìš© |\n",
    "| **ì¦ê°• ìœ í˜•** | ê¸°í•˜í•™ì , ìƒ‰ìƒ ë³€í™˜ | ë¬¸ì„œ ì†ìƒ, ìŠ¤ìº” ì•„í‹°íŒ©íŠ¸ |\n",
    "| **í˜„ì‹¤ì„±** | í•©ì„± ëŠë‚Œ | ì‹¤ì œ ë¬¸ì„œì²˜ëŸ¼ |\n",
    "| **ì†ë„** | ë§¤ìš° ë¹ ë¦„ | ì¤‘ê°„ |\n",
    "| **í•™ìŠµ ê³¡ì„ ** | ì‰¬ì›€ | ì¤‘ê°„ |\n",
    "| **ì´ ëŒ€íšŒ ì í•©ë„** | â­â­â­â­ | â­â­â­â­â­ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ ì–¸ì œ Augraphyë¥¼ ì‚¬ìš©í• ê¹Œ?\n",
    "\n",
    "âœ… **Augraphyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”**:\n",
    "- ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ (ì´ ëŒ€íšŒ!)\n",
    "- í…ŒìŠ¤íŠ¸ì…‹ì— ìŠ¤ìº”/ë³µì‚¬ ë…¸ì´ì¦ˆê°€ ë§ì„ ë•Œ\n",
    "- ì‹¤ì œ ë¬¸ì„œ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³  ì‹¶ì„ ë•Œ\n",
    "- Albumentationsë¡œ ì„±ëŠ¥ì´ ì •ì²´ë˜ì—ˆì„ ë•Œ\n",
    "\n",
    "âœ… **Albumentationsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”**:\n",
    "- ì¼ë°˜ ì´ë¯¸ì§€ ë¶„ë¥˜\n",
    "- ë¹ ë¥¸ ì‹¤í—˜ì´ í•„ìš”í•  ë•Œ\n",
    "- ê¸°ë³¸ ê¸°í•˜í•™ì  ë³€í™˜ë§Œ í•„ìš”í•  ë•Œ\n",
    "\n",
    "ğŸ’¡ **ë‘˜ ë‹¤ ì‚¬ìš©í•˜ì„¸ìš”** (ì•™ìƒë¸”):\n",
    "- Augraphy ëª¨ë¸ + Albumentations ëª¨ë¸ ì•™ìƒë¸”\n",
    "- ê°ê°ì˜ ì¥ì ì„ ëª¨ë‘ í™œìš©!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ì‹¤í—˜ ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "### ì‹œë‚˜ë¦¬ì˜¤ 1: Augraphy í…ŒìŠ¤íŠ¸\n",
    "1. B0 + Augraphy Light â†’ 35ë¶„ (F1: 0.76)\n",
    "2. B0 + Augraphy Medium â†’ 40ë¶„ (F1: 0.80)\n",
    "3. B0 + Augraphy Heavy â†’ 45ë¶„ (F1: 0.83)\n",
    "4. B1 + Augraphy Heavy â†’ 50ë¶„ (F1: 0.86)\n",
    "\n",
    "### ì‹œë‚˜ë¦¬ì˜¤ 2: ì•™ìƒë¸” ì „ëµ\n",
    "1. Albumentations ëª¨ë¸ í•™ìŠµ (baseline)\n",
    "2. Augraphy ëª¨ë¸ í•™ìŠµ (document-specific)\n",
    "3. ë‘ ëª¨ë¸ ì•™ìƒë¸” â†’ +2-3% ì„±ëŠ¥ í–¥ìƒ!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…\n",
    "\n",
    "### Augraphy ì„¤ì¹˜ ì˜¤ë¥˜\n",
    "```python\n",
    "!pip install augraphy\n",
    "# ë˜ëŠ”\n",
    "!pip install git+https://github.com/sparkfish/augraphy.git\n",
    "```\n",
    "\n",
    "### ì¦ê°•ì´ ë„ˆë¬´ ëŠë¦¼\n",
    "- Light ë ˆë²¨ ì‚¬ìš©\n",
    "- Batch size ì¤„ì´ê¸°\n",
    "- num_workers ì¡°ì •\n",
    "\n",
    "### ì¦ê°•ì´ ë„ˆë¬´ ê°•í•¨\n",
    "- ì„¹ì…˜ 9ì—ì„œ ì‹œê°í™” í™•ì¸\n",
    "- Light ë ˆë²¨ë¡œ ë³€ê²½\n",
    "- ê°œë³„ augmentation í™•ë¥  ì¡°ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install timm wandb augraphy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os",
    "import random",
    "import numpy as np",
    "import pandas as pd",
    "from PIL import Image",
    "import cv2",
    "from tqdm import tqdm",
    "import warnings",
    "warnings.filterwarnings('ignore')",
    "",
    "import torch",
    "import torch.nn as nn",
    "import torch.optim as optim",
    "from torch.utils.data import Dataset, DataLoader",
    "import torchvision.transforms as transforms",
    "",
    "# Augraphy ì„í¬íŠ¸",
    "import augraphy",
    "from augraphy import *",
    "",
    "import timm",
    "from sklearn.model_selection import train_test_split, StratifiedKFold",
    "from sklearn.metrics import f1_score, confusion_matrix",
    "",
    "import wandb",
    "",
    "# ============================",
    "# í™˜ê²½ ìë™ ê°ì§€ ë° GPU ì„¤ì •",
    "# ============================",
    "def get_device():",
    "    \"\"\"ë§¥/ìœˆë„ìš°/ë¦¬ëˆ…ìŠ¤ í™˜ê²½ ìë™ ê°ì§€ ë° ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ\"\"\"",
    "    if torch.cuda.is_available():",
    "        device = torch.device('cuda')",
    "        device_name = torch.cuda.get_device_name(0)",
    "        print(f'âœ“ CUDA ì‚¬ìš© ê°€ëŠ¥')",
    "        print(f'  GPU: {device_name}')",
    "    elif torch.backends.mps.is_available():",
    "        device = torch.device('mps')",
    "        print(f'âœ“ Apple Silicon MPS ì‚¬ìš© ê°€ëŠ¥')",
    "        print(f'  Metal Performance Shaders ê°€ì† í™œì„±í™”')",
    "    else:",
    "        device = torch.device('cpu')",
    "        print(f'âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.')",
    "    ",
    "    return device",
    "",
    "device = get_device()",
    "print(f'\\nUsing device: {device}')",
    "print(f'PyTorch version: {torch.__version__}')",
    "print(f'Augraphy version: {augraphy.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "source": "# í™˜ê²½ ìë™ ê°ì§€ (Google Colab vs Local)\nimport sys\n\ntry:\n    import google.colab\n    IS_COLAB = True\n    print(\"ğŸŒ Running on Google Colab\")\nexcept:\n    IS_COLAB = False\n    print(\"ğŸ’» Running on Local Machine\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì‹œë“œ ê³ ì • (ì¬í˜„ì„±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Google Drive ë§ˆìš´íŠ¸ (Colab only)\nif IS_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"âœ“ Google Drive mounted\")\nelse:\n    print(\"âœ“ Local environment - skipping drive mount\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# WandB ë¡œê·¸ì¸",
    "if Config.use_wandb if 'Config' in dir() else True:",
    "    if IS_COLAB:",
    "        wandb.login()  # Colabì—ì„œëŠ” ë§¤ë²ˆ ë¡œê·¸ì¸ í•„ìš”",
    "        print(\"âœ“ WandB login required on Colab\")",
    "    else:",
    "        # ë¡œì»¬ì€ ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆë‹¤ê³  ê°€ì •",
    "        print(\"âœ“ Using local WandB credentials\")",
    "",
    "WANDB_PROJECT = \"document-classification\"",
    "WANDB_ENTITY = None"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_IMG_SIZES = {    'efficientnet_b0': 384,    'efficientnet_b1': 416,    'efficientnet_b2': 448,    'efficientnet_b3': 512,    'convnext_tiny': 384,    'convnext_small': 384,}class Config:    # í™˜ê²½ë³„ ê²½ë¡œ ì„¤ì •    if IS_COLAB:        data_dir = '/content/drive/MyDrive/deep_learning_IC/data'        drive_model_dir = '/content/drive/MyDrive/deep_learning_IC/models'        save_to_drive = True    else:        data_dir = './data'  # ë¡œì»¬ ë°ì´í„° ê²½ë¡œ        drive_model_dir = './models'  # ë¡œì»¬ ëª¨ë¸ ì €ì¥ ê²½ë¡œ        save_to_drive = True  # ë¡œì»¬ì—ì„œë„ models í´ë”ì— ì €ì¥        train_dir = f'{data_dir}/train'    test_dir = f'{data_dir}/test'        # ë¡œì»¬ ëª¨ë¸ ì €ì¥ ê²½ë¡œ    local_model_path = './best_model.pth'  # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì„ì‹œ ì €ì¥        # ëª¨ë¸ ì„¤ì •    model_name = 'efficientnet_b0'    num_classes = 10    img_size = MODEL_IMG_SIZES.get(model_name, 384)        # í•™ìŠµ ì„¤ì •    epochs = 30    batch_size = 32    learning_rate = 1e-4    weight_decay = 1e-5        # Early Stopping    early_stopping_patience = 3    early_stopping_min_delta = 0.0001        # ë°ì´í„° ë¶„í•     val_ratio = 0.2        # Augraphy ì¦ê°• ê°•ë„    # 'light': ì•½í•œ ë¬¸ì„œ ì¦ê°•    # 'medium': ì¤‘ê°„ ë¬¸ì„œ ì¦ê°• (ê¶Œì¥)    # 'heavy': ê°•í•œ ë¬¸ì„œ ì¦ê°•    augmentation_level = 'medium'        # WandB    use_wandb = True    wandb_project = WANDB_PROJECT    wandb_entity = WANDB_ENTITY    experiment_name = None    experiment_prefix = None        # ì‹¤í—˜ ëª¨ë“œ ì„¤ì •    experiment_mode = True  # Trueë©´ CIFAR-10 ì‚¬ìš©, Falseë©´ ì‹¤ì œ ëŒ€íšŒ ë°ì´í„° ì‚¬ìš©    sample_ratio = 0.1  # ì‹¤í—˜ ì‹œ ì‚¬ìš©í•  ë°ì´í„° ë¹„ìœ¨ (0.1 = 10%)        # ê¸°íƒ€    num_workers = 2    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================",
    "# CIFAR-10 ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„",
    "# ============================",
    "",
    "if Config.experiment_mode:",
    "    print(\"\\n\" + \"=\"*70)",
    "    print(\"ğŸ§ª ì‹¤í—˜ ëª¨ë“œ: CIFAR-10 ë°ì´í„°ì…‹ ì‚¬ìš©\")",
    "    print(f\"ğŸ“Š ìƒ˜í”Œë§ ë¹„ìœ¨: {Config.sample_ratio*100:.0f}%\")",
    "    print(\"=\"*70 + \"\\n\")",
    "    ",
    "    import torchvision",
    "    import torchvision.transforms as transforms",
    "    from collections import defaultdict",
    "    ",
    "    # CIFAR-10 ë‹¤ìš´ë¡œë“œ",
    "    print(\"ğŸ“¥ CIFAR-10 ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...\")",
    "    cifar10_train = torchvision.datasets.CIFAR10(",
    "        root='./data/cifar10', ",
    "        train=True, ",
    "        download=True",
    "    )",
    "    cifar10_test = torchvision.datasets.CIFAR10(",
    "        root='./data/cifar10', ",
    "        train=False, ",
    "        download=True",
    "    )",
    "    ",
    "    # CIFAR-10 í´ë˜ìŠ¤ ì´ë¦„",
    "    cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', ",
    "                       'dog', 'frog', 'horse', 'ship', 'truck']",
    "    ",
    "    print(f\"âœ“ Train ìƒ˜í”Œ: {len(cifar10_train)}ê°œ\")",
    "    print(f\"âœ“ Test ìƒ˜í”Œ: {len(cifar10_test)}ê°œ\")",
    "    print(f\"âœ“ í´ë˜ìŠ¤: {cifar10_classes}\\n\")",
    "    ",
    "    # ì‹¤í—˜ìš© ìƒ˜í”Œë§ (í´ë˜ìŠ¤ë³„ ê· ë“± ìƒ˜í”Œë§)",
    "    def sample_cifar10(dataset, sample_ratio, seed=42):",
    "        \"\"\"í´ë˜ìŠ¤ë³„ë¡œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§\"\"\"",
    "        np.random.seed(seed)",
    "        ",
    "        # í´ë˜ìŠ¤ë³„ë¡œ ì¸ë±ìŠ¤ ê·¸ë£¹í™”",
    "        class_indices = defaultdict(list)",
    "        for idx, (_, label) in enumerate(dataset):",
    "            class_indices[label].append(idx)",
    "        ",
    "        # ê° í´ë˜ìŠ¤ì—ì„œ sample_ratioë§Œí¼ ìƒ˜í”Œë§",
    "        sampled_indices = []",
    "        for label, indices in class_indices.items():",
    "            n_samples = int(len(indices) * sample_ratio)",
    "            sampled = np.random.choice(indices, size=n_samples, replace=False)",
    "            sampled_indices.extend(sampled)",
    "        ",
    "        return sorted(sampled_indices)",
    "    ",
    "    # ìƒ˜í”Œë§ ì ìš©",
    "    if Config.sample_ratio < 1.0:",
    "        train_indices = sample_cifar10(cifar10_train, Config.sample_ratio, Config.seed)",
    "        test_indices = sample_cifar10(cifar10_test, Config.sample_ratio, Config.seed)",
    "        ",
    "        print(f\"ğŸ“Š ìƒ˜í”Œë§ ê²°ê³¼:\")",
    "        print(f\"  Train: {len(cifar10_train)} â†’ {len(train_indices)} ({Config.sample_ratio*100:.0f}%)\")",
    "        print(f\"  Test: {len(cifar10_test)} â†’ {len(test_indices)} ({Config.sample_ratio*100:.0f}%)\")",
    "    else:",
    "        train_indices = list(range(len(cifar10_train)))",
    "        test_indices = list(range(len(cifar10_test)))",
    "    ",
    "    # ë°ì´í„°ë¥¼ Augraphy í˜•ì‹ìœ¼ë¡œ ë³€í™˜",
    "    train_paths = []",
    "    train_labels = []",
    "    for idx in train_indices:",
    "        img, label = cifar10_train[idx]",
    "        train_paths.append(img)  # PIL Image ì €ì¥",
    "        train_labels.append(label)",
    "    ",
    "    test_paths = []",
    "    test_labels = []",
    "    for idx in test_indices:",
    "        img, label = cifar10_test[idx]",
    "        test_paths.append(img)",
    "        test_labels.append(label)",
    "    ",
    "    # í´ë˜ìŠ¤ ë§¤í•‘",
    "    class_to_idx = {name: idx for idx, name in enumerate(cifar10_classes)}",
    "    idx_to_class = {idx: name for name, idx in class_to_idx.items()}",
    "    ",
    "    # Config ì—…ë°ì´íŠ¸",
    "    Config.num_classes = 10",
    "    Config.img_size = 32  # CIFAR-10ì€ 32x32",
    "    ",
    "    print(f\"\\nâœ“ CIFAR-10 ì‹¤í—˜ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!\")",
    "    print(f\"  Train: {len(train_paths)}ê°œ\")",
    "    print(f\"  Test: {len(test_paths)}ê°œ\")",
    "    print(f\"  Image size: {Config.img_size}x{Config.img_size}\")",
    "    print(f\"  Classes: {Config.num_classes}\\n\")",
    "    ",
    "else:",
    "    print(\"\\n\" + \"=\"*70)",
    "    print(\"ğŸ† ì‹¤ì œ ëŒ€íšŒ ëª¨ë“œ: ëŒ€íšŒ ë°ì´í„°ì…‹ ì‚¬ìš©\")",
    "    print(\"=\"*70 + \"\\n\")",
    "    ",
    "    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ë¡œì§ (train.csv + meta.csv)",
    "    # ì´ ë¶€ë¶„ì€ ê¸°ì¡´ ì½”ë“œ ì‚¬ìš©",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ë¡œì»¬ í™˜ê²½ì—ì„œ í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±",
    "if not IS_COLAB:",
    "    os.makedirs(Config.data_dir, exist_ok=True)",
    "    os.makedirs(Config.drive_model_dir, exist_ok=True)",
    "    print(f\"âœ“ Local directories ready:\")",
    "    print(f\"  - Data: {Config.data_dir}\")",
    "    print(f\"  - Models: {Config.drive_model_dir}\")",
    "else:",
    "    print(f\"âœ“ Colab environment - using drive paths:\")",
    "    print(f\"  - Data: {Config.data_dir}\")",
    "    print(f\"  - Models: {Config.drive_model_dir}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Augraphy ë°ì´í„°ì…‹ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugraphyDataset(Dataset):",
    "    \"\"\"",
    "    Augraphyë¥¼ ì‚¬ìš©í•˜ëŠ” ë°ì´í„°ì…‹ í´ë˜ìŠ¤",
    "    ",
    "    AugraphyëŠ” PIL Image ë˜ëŠ” numpy ë°°ì—´ì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.",
    "    \"\"\"",
    "    def __init__(self, image_paths, labels=None, augraphy_pipeline=None, transform=None):",
    "        self.image_paths = image_paths",
    "        self.labels = labels",
    "        self.augraphy_pipeline = augraphy_pipeline",
    "        self.transform = transform",
    "    ",
    "    def __len__(self):",
    "        return len(self.image_paths)",
    "    ",
    "    def __getitem__(self, idx):",
    "        img_path = self.image_paths[idx]",
    "        ",
    "        # ì´ë¯¸ì§€ ë¡œë“œ (numpy ë°°ì—´)",
    "        image = cv2.imread(img_path)",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)",
    "        ",
    "        # Augraphy ì¦ê°• ì ìš©",
    "        if self.augraphy_pipeline:",
    "            image = self.augraphy_pipeline(image)",
    "        ",
    "        # PIL Imageë¡œ ë³€í™˜ (torchvision transforms í˜¸í™˜)",
    "        image = Image.fromarray(image)",
    "        ",
    "        # PyTorch transforms ì ìš©",
    "        if self.transform:",
    "            image = self.transform(image)",
    "        ",
    "        if self.labels is not None:",
    "            label = self.labels[idx]",
    "            return image, label",
    "        else:",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Augraphy ì¦ê°• íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "### ë¬¸ì„œ ì´ë¯¸ì§€ íŠ¹í™” ì¦ê°•\n",
    "\n",
    "AugraphyëŠ” ì‹¤ì œ ë¬¸ì„œì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ì†ìƒ/ë³€í˜•ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤:\n",
    "\n",
    "#### ğŸ“„ **Ink Phase**: ì‰í¬/í”„ë¦°íŠ¸ ê´€ë ¨\n",
    "- InkBleed: ì‰í¬ ë²ˆì§\n",
    "- DirtyDrum: ë“œëŸ¼ ì˜¤ì—¼ (ë³µì‚¬ê¸°)\n",
    "- DirtyRollers: ë¡¤ëŸ¬ ì˜¤ì—¼\n",
    "\n",
    "#### ğŸ“ƒ **Paper Phase**: ì¢…ì´ ì§ˆê°/ìƒíƒœ\n",
    "- PaperFactory: ì¢…ì´ ì§ˆê°\n",
    "- ColorPaper: ìƒ‰ìƒ ì¢…ì´\n",
    "- WaterMark: ì›Œí„°ë§ˆí¬\n",
    "\n",
    "#### ğŸ“  **Post Phase**: ìŠ¤ìº”/ì´¬ì˜ í›„ì²˜ë¦¬\n",
    "- Brightness: ë°ê¸°\n",
    "- BleedThrough: ë’·ë©´ ë¹„ì¹¨\n",
    "- SubtleNoise: ìŠ¤ìº” ë…¸ì´ì¦ˆ\n",
    "- Jpeg Compression: ì••ì¶• ì•„í‹°íŒ©íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augraphy_pipeline(level='medium'):",
    "    \"\"\"",
    "    ë¬¸ì„œ ì´ë¯¸ì§€ ì¦ê°• íŒŒì´í”„ë¼ì¸ ìƒì„±",
    "    ",
    "    Args:",
    "        level: 'light', 'medium', 'heavy'",
    "    \"\"\"",
    "    ",
    "    if level == 'light':",
    "        # ì•½í•œ ë¬¸ì„œ ì¦ê°•",
    "        ink_phase = [",
    "            InkBleed(intensity_range=(0.1, 0.2), p=0.3),",
    "        ]",
    "        ",
    "        paper_phase = [",
    "            PaperFactory(p=0.3),",
    "        ]",
    "        ",
    "        post_phase = [",
    "            Brightness(brightness_range=(0.9, 1.1), p=0.5),",
    "            SubtleNoise(p=0.3),",
    "        ]",
    "    ",
    "    elif level == 'medium':",
    "        # ì¤‘ê°„ ë¬¸ì„œ ì¦ê°• (ê¶Œì¥)",
    "        ink_phase = [",
    "            InkBleed(intensity_range=(0.1, 0.3), p=0.5),",
    "            DirtyDrum(intensity_range=(0.5, 0.8), p=0.3),",
    "        ]",
    "        ",
    "        paper_phase = [",
    "            PaperFactory(p=0.5),",
    "            ColorPaper(hue_range=(0, 28), saturation_range=(0, 10), p=0.3),",
    "            WaterMark(watermark_word=\"\", watermark_font_size=(10, 15), ",
    "                     watermark_font_thickness=(1, 2), p=0.2),",
    "        ]",
    "        ",
    "        post_phase = [",
    "            Brightness(brightness_range=(0.85, 1.15), p=0.6),",
    "            BleedThrough(intensity_range=(0.1, 0.3), p=0.3),",
    "            SubtleNoise(p=0.5),",
    "            LightingGradient(light_position=(0, 2), direction=(0, 3), ",
    "                           max_brightness=255, min_brightness=0, ",
    "                           transparency=0.5, p=0.3),",
    "            Jpeg(quality_range=(70, 95), p=0.3),",
    "        ]",
    "    ",
    "    elif level == 'heavy':",
    "        # ê°•í•œ ë¬¸ì„œ ì¦ê°•",
    "        ink_phase = [",
    "            InkBleed(intensity_range=(0.1, 0.4), p=0.7),",
    "            DirtyDrum(intensity_range=(0.4, 0.9), p=0.5),",
    "            DirtyRollers(intensity_range=(0.4, 0.9), p=0.3),",
    "        ]",
    "        ",
    "        paper_phase = [",
    "            PaperFactory(p=0.7),",
    "            ColorPaper(hue_range=(0, 28), saturation_range=(0, 15), p=0.5),",
    "            WaterMark(watermark_word=\"\", watermark_font_size=(8, 20),",
    "                     watermark_font_thickness=(1, 3), p=0.3),",
    "            PageBorder(border_width_range=(1, 3), border_color=(0, 0, 0), p=0.3),",
    "        ]",
    "        ",
    "        post_phase = [",
    "            Brightness(brightness_range=(0.8, 1.2), p=0.7),",
    "            BleedThrough(intensity_range=(0.1, 0.4), p=0.5),",
    "            SubtleNoise(p=0.7),",
    "            LightingGradient(light_position=(0, 2), direction=(0, 3),",
    "                           max_brightness=255, min_brightness=0,",
    "                           transparency=0.5, p=0.5),",
    "            DirtyDrum(intensity_range=(0.5, 0.9), p=0.4),",
    "            Jpeg(quality_range=(60, 95), p=0.5),",
    "            Faxify(scale_range=(0.3, 0.6), monochrome=0, ",
    "                  monochrome_method=\"random\", p=0.2),",
    "        ]",
    "    ",
    "    else:",
    "        raise ValueError(f\"Unknown level: {level}\")",
    "    ",
    "    # íŒŒì´í”„ë¼ì¸ ìƒì„±",
    "    pipeline = AugraphyPipeline(",
    "        ink_phase=ink_phase,",
    "        paper_phase=paper_phase,",
    "        post_phase=post_phase",
    "    )",
    "    ",
    "    return pipeline",
    "",
    "",
    "# PyTorch Transforms (ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”)",
    "train_transform = transforms.Compose([",
    "    transforms.Resize((Config.img_size, Config.img_size)),",
    "    transforms.ToTensor(),",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],",
    "                       std=[0.229, 0.224, 0.225])",
    "])",
    "",
    "val_transform = transforms.Compose([",
    "    transforms.Resize((Config.img_size, Config.img_size)),",
    "    transforms.ToTensor(),",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],",
    "                       std=[0.229, 0.224, 0.225])",
    "])",
    "",
    "# Augraphy íŒŒì´í”„ë¼ì¸ ìƒì„±",
    "augraphy_pipeline = get_augraphy_pipeline(level=Config.augmentation_level)",
    "",
    "print(f\"Augraphy level: {Config.augmentation_level}\")",
    "print(f\"Pipeline created with {len(augraphy_pipeline.ink_phase) + len(augraphy_pipeline.paper_phase) + len(augraphy_pipeline.post_phase)} augmentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n\n**ì£¼ì˜**: ì´ ì½”ë“œëŠ” ì œê³µëœ ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë§ê²Œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në°ì´í„° êµ¬ì¡°:\n```\ndata/\nâ”œâ”€â”€ train.csv       (ID, target)\nâ”œâ”€â”€ meta.csv        (target, class_name)\nâ”œâ”€â”€ train/          (ì´ë¯¸ì§€ íŒŒì¼ë“¤)\nâ”‚   â”œâ”€â”€ image1.jpg\nâ”‚   â”œâ”€â”€ image2.jpg\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ test/           (í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ë“¤)\n    â”œâ”€â”€ test1.jpg\n    â””â”€â”€ ...\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (train.csv + meta.csv ê¸°ë°˜)",
    "def load_data_from_csv(train_csv_path, meta_csv_path, train_dir):",
    "    \"\"\"",
    "    train.csvì™€ meta.csvë¥¼ ì½ì–´ì„œ ë°ì´í„° ë¡œë“œ",
    "",
    "    Args:",
    "        train_csv_path: 'train.csv' ê²½ë¡œ (ID, target)",
    "        meta_csv_path: 'meta.csv' ê²½ë¡œ (target, class_name)",
    "        train_dir: í•™ìŠµ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ",
    "",
    "    Returns:",
    "        image_paths, labels, class_to_idx",
    "    \"\"\"",
    "    # train.csv ì½ê¸° (ID, target)",
    "    train_df = pd.read_csv(train_csv_path)",
    "    print(f\"train.csv loaded: {len(train_df)} entries\")",
    "",
    "    # meta.csv ì½ê¸° (target, class_name)",
    "    meta_df = pd.read_csv(meta_csv_path)",
    "    print(f\"meta.csv loaded: {len(meta_df)} classes\")",
    "",
    "    # class_to_idx ë§¤í•‘ ìƒì„± (class_name â†’ target)",
    "    class_to_idx = dict(zip(meta_df['class_name'], meta_df['target']))",
    "",
    "    # idx_to_class ë§¤í•‘ ìƒì„± (target â†’ class_name)",
    "    idx_to_class = dict(zip(meta_df['target'], meta_df['class_name']))",
    "",
    "    # ì´ë¯¸ì§€ ê²½ë¡œì™€ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ ìƒì„±",
    "    image_paths = []",
    "    labels = []",
    "    missing_count = 0",
    "",
    "    for _, row in train_df.iterrows():",
    "        img_id = row['ID']",
    "        target = row['target']",
    "",
    "        # ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± (í™•ì¥ìê°€ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ë„ ìˆìŒ)",
    "        img_path = os.path.join(train_dir, img_id)",
    "",
    "        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸",
    "        if os.path.exists(img_path):",
    "            image_paths.append(img_path)",
    "            labels.append(target)",
    "        else:",
    "            # í™•ì¥ìë¥¼ ì‹œë„í•´ë³´ê¸°",
    "            found = False",
    "            for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:",
    "                img_path_with_ext = os.path.join(train_dir, img_id + ext) if not img_id.endswith(ext) else img_path",
    "                if os.path.exists(img_path_with_ext):",
    "                    image_paths.append(img_path_with_ext)",
    "                    labels.append(target)",
    "                    found = True",
    "                    break",
    "",
    "            if not found:",
    "                missing_count += 1",
    "",
    "    if missing_count > 0:",
    "        print(f\"Warning: {missing_count} images from train.csv not found in {train_dir}\")",
    "",
    "    print(f\"\\nSuccessfully loaded {len(image_paths)} images\")",
    "    print(f\"Number of classes: {len(class_to_idx)}\")",
    "    print(f\"\\nClasses:\")",
    "    for class_name, idx in sorted(class_to_idx.items(), key=lambda x: x[1]):",
    "        print(f\"  [{idx}] {class_name}\")",
    "",
    "    return image_paths, labels, class_to_idx",
    "",
    "# í•™ìŠµ ë°ì´í„° ë¡œë“œ",
    "train_csv_path = './data/train.csv'",
    "meta_csv_path = './data/meta.csv'",
    "",
    "if os.path.exists(train_csv_path) and os.path.exists(meta_csv_path) and os.path.exists(Config.train_dir):",
    "    train_paths, train_labels, class_to_idx = load_data_from_csv(train_csv_path, meta_csv_path, Config.train_dir)",
    "",
    "    # Config.num_classes ì—…ë°ì´íŠ¸",
    "    Config.num_classes = len(class_to_idx)",
    "else:",
    "    missing_files = []",
    "    if not os.path.exists(train_csv_path):",
    "        missing_files.append(train_csv_path)",
    "    if not os.path.exists(meta_csv_path):",
    "        missing_files.append(meta_csv_path)",
    "    if not os.path.exists(Config.train_dir):",
    "        missing_files.append(Config.train_dir)",
    "",
    "    print(f\"Error: Missing required files/directories:\")",
    "    for f in missing_files:",
    "        print(f\"  - {f}\")",
    "    print(\"\\nPlease upload your data or modify the paths in Config.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\ndef visualize_random_samples(image_paths, labels, class_to_idx, num_samples=5):\n    \"\"\"\n    ë°ì´í„°ì…‹ì—ì„œ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ì—¬ ì‹œê°í™”\n    \n    Args:\n        image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n        labels: ë¼ë²¨ ë¦¬ìŠ¤íŠ¸\n        class_to_idx: í´ë˜ìŠ¤ëª…-ì¸ë±ìŠ¤ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n        num_samples: ì‹œê°í™”í•  ìƒ˜í”Œ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)\n    \"\"\"\n    # ì¸ë±ìŠ¤-í´ë˜ìŠ¤ëª… ë§¤í•‘\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    \n    # ëœë¤ ì¸ë±ìŠ¤ ì„ íƒ\n    random_indices = random.sample(range(len(image_paths)), min(num_samples, len(image_paths)))\n    \n    # í”Œë¡¯ ìƒì„±\n    fig, axes = plt.subplots(1, len(random_indices), figsize=(4 * len(random_indices), 4))\n    if len(random_indices) == 1:\n        axes = [axes]\n    \n    for idx, img_idx in enumerate(random_indices):\n        # ì´ë¯¸ì§€ ë¡œë“œ\n        img_path = image_paths[img_idx]\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # í´ë˜ìŠ¤ëª… ê°€ì ¸ì˜¤ê¸°\n        label_idx = labels[img_idx]\n        class_name = idx_to_class[label_idx]\n        \n        # ì‹œê°í™”\n        axes[idx].imshow(image)\n        axes[idx].set_title(f'Class: {class_name}\\n({os.path.basename(img_path)})', fontsize=10)\n        axes[idx].axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# ë°ì´í„°ê°€ ë¡œë“œëœ ê²½ìš° ëœë¤ ìƒ˜í”Œ ì‹œê°í™”\nif 'train_paths' in locals() and len(train_paths) > 0:\n    print(f\"\\n{'='*60}\")\n    print(\"ë°ì´í„°ì…‹ì—ì„œ ëœë¤ìœ¼ë¡œ 5ê°œ ìƒ˜í”Œ ì¶”ì¶œ (ì›ë³¸ ì´ë¯¸ì§€)\")\n    print(f\"{'='*60}\\n\")\n    visualize_random_samples(train_paths, train_labels, class_to_idx, num_samples=5)\n    \n    # í´ë˜ìŠ¤ë³„ ë¶„í¬ ì¶œë ¥\n    print(f\"\\n{'='*60}\")\n    print(\"í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜:\")\n    print(f\"{'='*60}\")\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    class_counts = {}\n    for label in train_labels:\n        class_name = idx_to_class[label]\n        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n    \n    for class_name in sorted(class_counts.keys()):\n        print(f\"  {class_name}: {class_counts[class_name]:4d} images\")\n    print(f\"{'='*60}\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8-1. ë°ì´í„°ì…‹ í™•ì¸ (ëœë¤ ìƒ˜í”Œ 5ê°œ ì‹œê°í™”)\n\në¡œë“œí•œ ë°ì´í„°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ê° í´ë˜ìŠ¤ì—ì„œ ëœë¤ìœ¼ë¡œ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 8-2. ì¶”ê°€ ë°ì´í„° ë¶„ì„ (EDA)\n\në°ì´í„°ì˜ íŠ¹ì„±ì„ ë” ìì„¸íˆ íŒŒì•…í•˜ê¸° ìœ„í•œ ì‹œê°í™”ì…ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\n\ndef visualize_class_distribution(labels, class_to_idx):\n    \"\"\"Visualize the distribution of classes in the dataset\"\"\"\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    class_names = [idx_to_class[label] for label in labels]\n    class_counts = Counter(class_names)\n    \n    classes = list(class_counts.keys())\n    counts = list(class_counts.values())\n    \n    plt.figure(figsize=(12, 6))\n    bars = plt.bar(classes, counts)\n    plt.xlabel('Class')\n    plt.ylabel('Number of Images')\n    plt.title('Class Distribution in Training Dataset')\n    plt.xticks(rotation=45, ha='right')\n    \n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height,\n                f'{int(height)}',\n                ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(\"\\nClass distribution:\")\n    for class_name, count in sorted(class_counts.items()):\n        print(f\"{class_name}: {count} images\")\n\ndef analyze_image_resolutions(image_paths, num_samples=None):\n    \"\"\"Analyze and visualize image resolution distribution\"\"\"\n    from PIL import Image\n    \n    if num_samples:\n        sample_paths = np.random.choice(image_paths, min(num_samples, len(image_paths)), replace=False)\n    else:\n        sample_paths = image_paths\n    \n    widths = []\n    heights = []\n    \n    for img_path in sample_paths:\n        try:\n            with Image.open(img_path) as img:\n                w, h = img.size\n                widths.append(w)\n                heights.append(h)\n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n    \n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    \n    axes[0].hist(widths, bins=30, edgecolor='black')\n    axes[0].set_xlabel('Width (pixels)')\n    axes[0].set_ylabel('Frequency')\n    axes[0].set_title('Image Width Distribution')\n    axes[0].axvline(np.mean(widths), color='r', linestyle='--', label=f'Mean: {np.mean(widths):.0f}')\n    axes[0].legend()\n    \n    axes[1].hist(heights, bins=30, edgecolor='black')\n    axes[1].set_xlabel('Height (pixels)')\n    axes[1].set_ylabel('Frequency')\n    axes[1].set_title('Image Height Distribution')\n    axes[1].axvline(np.mean(heights), color='r', linestyle='--', label=f'Mean: {np.mean(heights):.0f}')\n    axes[1].legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nResolution Statistics (from {len(widths)} images):\")\n    print(f\"Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.0f}\")\n    print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.0f}\")\n\ndef visualize_class_grid(image_paths, labels, class_to_idx, samples_per_class=3):\n    \"\"\"Visualize random samples from each class in a grid\"\"\"\n    from PIL import Image\n    \n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    \n    class_images = {class_name: [] for class_name in class_to_idx.keys()}\n    for img_path, label in zip(image_paths, labels):\n        class_name = idx_to_class[label]\n        class_images[class_name].append(img_path)\n    \n    num_classes = len(class_to_idx)\n    fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(samples_per_class * 3, num_classes * 3))\n    \n    if num_classes == 1:\n        axes = axes.reshape(1, -1)\n    \n    for idx, (class_name, img_paths) in enumerate(sorted(class_images.items())):\n        sample_paths = np.random.choice(img_paths, min(samples_per_class, len(img_paths)), replace=False)\n        \n        for col, img_path in enumerate(sample_paths):\n            try:\n                img = Image.open(img_path)\n                axes[idx, col].imshow(img)\n                axes[idx, col].axis('off')\n                if col == 0:\n                    axes[idx, col].set_ylabel(class_name, rotation=0, ha='right', va='center', fontsize=12)\n            except Exception as e:\n                print(f\"Error loading {img_path}: {e}\")\n        \n        for col in range(len(sample_paths), samples_per_class):\n            axes[idx, col].axis('off')\n    \n    plt.suptitle('Random Samples from Each Class', fontsize=16, y=0.995)\n    plt.tight_layout()\n    plt.show()\n\nif 'train_paths' in locals() and len(train_paths) > 0:\n    print(\"=\" * 50)\n    print(\"EXPLORATORY DATA ANALYSIS\")\n    print(\"=\" * 50)\n    \n    print(\"\\n1. Class Distribution Analysis\")\n    print(\"-\" * 50)\n    visualize_class_distribution(train_labels, class_to_idx)\n    \n    print(\"\\n2. Image Resolution Analysis\")\n    print(\"-\" * 50)\n    analyze_image_resolutions(train_paths, num_samples=500)\n    \n    print(\"\\n3. Visual Sample Grid\")\n    print(\"-\" * 50)\n    visualize_class_grid(train_paths, train_labels, class_to_idx, samples_per_class=3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ì„¤ì •",
    "n_splits = 3",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=Config.seed)",
    "",
    "print(f\"\\n{'='*60}\")",
    "print(f\"3-Fold Cross Validation Ensemble Training\")",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì¦ê°• ê²°ê³¼ ì‹œê°í™” (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ì¦ê°•ì´ ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt",
    "",
    "def visualize_augmentations(dataset, idx=0, samples=5):",
    "    \"\"\"",
    "    ë°ì´í„°ì…‹ì˜ ì¦ê°• ê²°ê³¼ë¥¼ ì‹œê°í™”",
    "    ",
    "    Args:",
    "        dataset: AugraphyDataset ê°ì²´",
    "        idx: ì‹œê°í™”í•  ì´ë¯¸ì§€ì˜ ì¸ë±ìŠ¤",
    "        samples: ìƒì„±í•  ì¦ê°• ìƒ˜í”Œ ìˆ˜",
    "    \"\"\"",
    "    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ",
    "    img_path = dataset.image_paths[idx]",
    "    original_image = cv2.imread(img_path)",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)",
    "    ",
    "    # í”Œë¡¯ ìƒì„±",
    "    fig, axes = plt.subplots(1, samples + 1, figsize=(4 * (samples + 1), 4))",
    "    ",
    "    # ì›ë³¸ ì´ë¯¸ì§€",
    "    axes[0].imshow(original_image)",
    "    axes[0].set_title('Original', fontsize=12)",
    "    axes[0].axis('off')",
    "    ",
    "    # ì¦ê°•ëœ ì´ë¯¸ì§€ë“¤",
    "    for i in range(samples):",
    "        augmented = dataset.transform(image=original_image)",
    "        aug_image = augmented['image']",
    "        ",
    "        # í…ì„œë¥¼ numpyë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™” í•´ì œ",
    "        if isinstance(aug_image, torch.Tensor):",
    "            aug_image = aug_image.permute(1, 2, 0).numpy()",
    "            # ì •ê·œí™” í•´ì œ",
    "            mean = np.array([0.485, 0.456, 0.406])",
    "            std = np.array([0.229, 0.224, 0.225])",
    "            aug_image = std * aug_image + mean",
    "            aug_image = np.clip(aug_image, 0, 1)",
    "        ",
    "        axes[i + 1].imshow(aug_image)",
    "        axes[i + 1].set_title(f'Augmented {i+1}', fontsize=12)",
    "        axes[i + 1].axis('off')",
    "    ",
    "    plt.tight_layout()",
    "    plt.show()",
    "",
    "# ì¦ê°• ì‹œê°í™” (ë°ì´í„°ê°€ ë¡œë“œëœ ê²½ìš°)",
    "if 'train_dataset' in locals() and len(train_dataset) > 0:",
    "    print(f\"Visualizing augmentations with level: {Config.augmentation_level}\")",
    "    visualize_augmentations(train_dataset, idx=0, samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. WandB Run ì´ˆê¸°í™” (í•™ìŠµ ì‹œì‘ ì „)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_experiment_number(project_name, prefix, entity=None):",
    "    \"\"\"WandBì—ì„œ ê¸°ì¡´ ì‹¤í—˜ë“¤ì„ í™•ì¸í•˜ê³  ë‹¤ìŒ ë²ˆí˜¸ë¥¼ ë°˜í™˜\"\"\"",
    "    try:",
    "        api = wandb.Api()",
    "        # í”„ë¡œì íŠ¸ì˜ ëª¨ë“  run ê°€ì ¸ì˜¤ê¸°",
    "        if entity:",
    "            runs = api.runs(f\"{entity}/{project_name}\")",
    "        else:",
    "            runs = api.runs(project_name)",
    "        ",
    "        # prefixë¡œ ì‹œì‘í•˜ëŠ” runë“¤ì˜ ë²ˆí˜¸ ì¶”ì¶œ",
    "        numbers = []",
    "        for run in runs:",
    "            if run.name.startswith(prefix):",
    "                try:",
    "                    # 'prefix_123' í˜•íƒœì—ì„œ 123 ì¶”ì¶œ",
    "                    num = int(run.name.split('_')[-1])",
    "                    numbers.append(num)",
    "                except:",
    "                    continue",
    "        ",
    "        # ê°€ì¥ í° ë²ˆí˜¸ + 1 ë°˜í™˜",
    "        next_num = max(numbers) + 1 if numbers else 1",
    "        return next_num",
    "    except:",
    "        # API ì ‘ê·¼ ì‹¤íŒ¨ì‹œ 001ë¶€í„° ì‹œì‘",
    "        return 1",
    "",
    "# WandB Run ì´ˆê¸°í™”",
    "if Config.use_wandb:",
    "    # experiment_prefixê°€ Noneì´ë©´ ëª¨ë¸ëª… ì‚¬ìš© (ìë™)",
    "    if Config.experiment_prefix is None:",
    "        actual_prefix = f\"{Config.model_name}_aug_{Config.augmentation_level}\"",
    "    else:",
    "        actual_prefix = Config.experiment_prefix",
    "    ",
    "    # ì‹¤í—˜ëª… ìë™ ìƒì„±",
    "    if Config.experiment_name is None:",
    "        exp_num = get_next_experiment_number(",
    "            Config.wandb_project, ",
    "            actual_prefix,",
    "            Config.wandb_entity",
    "        )",
    "        Config.experiment_name = f\"{actual_prefix}_{exp_num:03d}\"",
    "    ",
    "    run = wandb.init(",
    "        project=Config.wandb_project,",
    "        entity=Config.wandb_entity,",
    "        name=Config.experiment_name,",
    "        config={",
    "            \"model_name\": Config.model_name,",
    "            \"num_classes\": Config.num_classes,",
    "            \"img_size\": Config.img_size,",
    "            \"epochs\": Config.epochs,",
    "            \"batch_size\": Config.batch_size,",
    "            \"learning_rate\": Config.learning_rate,",
    "            \"weight_decay\": Config.weight_decay,",
    "            \"optimizer\": \"AdamW\",",
    "            \"scheduler\": \"CosineAnnealingLR\",",
    "            \"val_ratio\": Config.val_ratio,",
    "            \"seed\": Config.seed,",
    "            \"augmentation\": \"albumentations\",",
    "            \"augmentation_level\": Config.augmentation_level,",
    "        }",
    "    )",
    "    print(f\"\\n{'='*60}\")",
    "    print(f\"WandB Run initialized: {run.name}\")",
    "    print(f\"WandB URL: {run.url}\")",
    "    print(f\"{'='*60}\\n\")",
    "else:",
    "    print(\"WandB is disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentClassifier(nn.Module):",
    "    def __init__(self, model_name, num_classes, pretrained=True):",
    "        super(DocumentClassifier, self).__init__()",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)",
    "        ",
    "        # ëª¨ë¸ì˜ classifier ë¶€ë¶„ ìˆ˜ì •",
    "        if 'efficientnet' in model_name:",
    "            in_features = self.model.classifier.in_features",
    "            self.model.classifier = nn.Linear(in_features, num_classes)",
    "        elif 'resnet' in model_name:",
    "            in_features = self.model.fc.in_features",
    "            self.model.fc = nn.Linear(in_features, num_classes)",
    "        elif 'vit' in model_name:",
    "            in_features = self.model.head.in_features",
    "            self.model.head = nn.Linear(in_features, num_classes)",
    "    ",
    "    def forward(self, x):",
    "        return self.model(x)",
    "",
    "# ëª¨ë¸ ìƒì„±",
    "model = DocumentClassifier(",
    "    model_name=Config.model_name, ",
    "    num_classes=Config.num_classes, ",
    "    pretrained=True",
    ").to(device)",
    "",
    "print(f\"Model: {Config.model_name}\")",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")",
    "",
    "# WandBì— ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œê¹…",
    "if Config.use_wandb:",
    "    wandb.watch(model, log='all', log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()",
    "optimizer = optim.AdamW(model.parameters(), lr=Config.learning_rate, weight_decay=Config.weight_decay)",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):",
    "    model.train()",
    "    running_loss = 0.0",
    "    correct = 0",
    "    total = 0",
    "    ",
    "    pbar = tqdm(train_loader, desc='Training')",
    "    for batch_idx, (images, labels) in enumerate(pbar):",
    "        images, labels = images.to(device), labels.to(device)",
    "        ",
    "        optimizer.zero_grad()",
    "        outputs = model(images)",
    "        loss = criterion(outputs, labels)",
    "        loss.backward()",
    "        optimizer.step()",
    "        ",
    "        running_loss += loss.item()",
    "        _, predicted = outputs.max(1)",
    "        total += labels.size(0)",
    "        correct += predicted.eq(labels).sum().item()",
    "        ",
    "        # ë°°ì¹˜ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°",
    "        batch_loss = running_loss / (batch_idx + 1)",
    "        batch_acc = 100. * correct / total",
    "        ",
    "        pbar.set_postfix({",
    "            'loss': batch_loss,",
    "            'acc': batch_acc",
    "        })",
    "        ",
    "        # WandB ë¡œê¹… (ë§¤ ë°°ì¹˜ë§ˆë‹¤)",
    "        if Config.use_wandb:",
    "            wandb.log({",
    "                'train/batch_loss': loss.item(),",
    "                'train/batch_acc': 100. * predicted.eq(labels).sum().item() / labels.size(0),",
    "                'train/step': epoch * len(train_loader) + batch_idx",
    "            })",
    "    ",
    "    epoch_loss = running_loss / len(train_loader)",
    "    epoch_acc = 100. * correct / total",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    \n",
    "    # Macro F1 Score ê³„ì‚°\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # í´ë˜ìŠ¤ë³„ F1 Score ê³„ì‚°\n",
    "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    # Confusion Matrix ê³„ì‚°\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, macro_f1, per_class_f1, cm, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. í•™ìŠµ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ì•™ìƒë¸” í•™ìŠµ ì‹œì‘",
    "fold_models = []  # ê° foldì˜ ëª¨ë¸ì„ ì €ì¥",
    "fold_results = []  # ê° foldì˜ ê²°ê³¼ë¥¼ ì €ì¥",
    "",
    "# ì „ì²´ íˆìŠ¤í† ë¦¬ ì €ì¥ìš©",
    "all_fold_history = {",
    "    'train_loss': [],",
    "    'train_acc': [],",
    "    'val_loss': [],",
    "    'val_f1': []",
    "}",
    "",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_paths, train_labels)):",
    "    print(f\"\\n{'='*60}\")",
    "    print(f\"Fold {fold+1}/{n_splits}\")",
    "    print(f\"{'='*60}\\n\")",
    "    ",
    "    # í˜„ì¬ foldì˜ train/val split",
    "    fold_train_paths = [train_paths[i] for i in train_idx]",
    "    fold_val_paths = [train_paths[i] for i in val_idx]",
    "    fold_train_labels = [train_labels[i] for i in train_idx]",
    "    fold_val_labels = [train_labels[i] for i in val_idx]",
    "    ",
    "    print(f\"Fold {fold+1} - Train size: {len(fold_train_paths)}\")",
    "    print(f\"Fold {fold+1} - Val size: {len(fold_val_paths)}\")",
    "    ",
    "    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„± (Augraphy pipeline ì ìš©)",
    "    fold_train_dataset = AugraphyDataset(fold_train_paths, fold_train_labels, ",
    "                                         augraphy_pipeline=augraphy_pipeline, transform=train_transform)",
    "    fold_val_dataset = AugraphyDataset(fold_val_paths, fold_val_labels, ",
    "                                       augraphy_pipeline=None, transform=val_transform)",
    "    ",
    "    train_loader = DataLoader(",
    "        fold_train_dataset,",
    "        batch_size=Config.batch_size,",
    "        shuffle=True,",
    "        num_workers=Config.num_workers",
    "    )",
    "    ",
    "    val_loader = DataLoader(",
    "        fold_val_dataset,",
    "        batch_size=Config.batch_size,",
    "        shuffle=False,",
    "        num_workers=Config.num_workers",
    "    )",
    "    ",
    "    # ìƒˆ ëª¨ë¸ ìƒì„± (ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ëª¨ë¸)",
    "    model = DocumentClassifier(",
    "        model_name=Config.model_name,",
    "        num_classes=Config.num_classes,",
    "        pretrained=True",
    "    ).to(device)",
    "    ",
    "    criterion = nn.CrossEntropyLoss()",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.learning_rate, weight_decay=Config.weight_decay)",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.epochs, eta_min=1e-6)",
    "    ",
    "    # WandBì— ëª¨ë¸ ì•„í‚¤í…ì²˜ ë¡œê¹… (ì²« ë²ˆì§¸ foldì—ë§Œ)",
    "    if Config.use_wandb and fold == 0:",
    "        wandb.watch(model, log='all', log_freq=100)",
    "    ",
    "    # Foldë³„ í•™ìŠµ",
    "    best_f1 = 0.0",
    "    patience_counter = 0",
    "    history = {",
    "        'train_loss': [],",
    "        'train_acc': [],",
    "        'val_loss': [],",
    "        'val_f1': []",
    "    }",
    "    ",
    "    # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì €ì¥ ê²½ë¡œ ìƒì„±",
    "    if Config.save_to_drive:",
    "        os.makedirs(Config.drive_model_dir, exist_ok=True)",
    "    ",
    "    for epoch in range(Config.epochs):",
    "        print(f\"\\nFold {fold+1} - Epoch {epoch+1}/{Config.epochs}\")",
    "        print(\"-\" * 50)",
    "        ",
    "        # í•™ìŠµ",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)",
    "        ",
    "        # ê²€ì¦",
    "        val_loss, val_f1, per_class_f1, cm, val_preds, val_labels_batch = validate(model, val_loader, criterion, device)",
    "        ",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸",
    "        scheduler.step()",
    "        current_lr = optimizer.param_groups[0]['lr']",
    "        ",
    "        # ê²°ê³¼ ì €ì¥",
    "        history['train_loss'].append(train_loss)",
    "        history['train_acc'].append(train_acc)",
    "        history['val_loss'].append(val_loss)",
    "        history['val_f1'].append(val_f1)",
    "        ",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Macro F1: {val_f1:.4f}\")",
    "        print(f\"Learning Rate: {current_lr:.6f}\")",
    "        ",
    "        # WandB ë¡œê¹…",
    "        if Config.use_wandb:",
    "            log_dict = {",
    "                'fold': fold + 1,",
    "                'epoch': epoch + 1,",
    "                f'fold{fold+1}/train_loss': train_loss,",
    "                f'fold{fold+1}/train_acc': train_acc,",
    "                f'fold{fold+1}/val_loss': val_loss,",
    "                f'fold{fold+1}/val_f1': val_f1,",
    "                f'fold{fold+1}/learning_rate': current_lr,",
    "                f'fold{fold+1}/patience_counter': patience_counter,",
    "            }",
    "            ",
    "            # í´ë˜ìŠ¤ë³„ F1 Score",
    "            if 'class_to_idx' in locals():",
    "                idx_to_class = {v: k for k, v in class_to_idx.items()}",
    "                for idx, f1 in enumerate(per_class_f1):",
    "                    class_name = idx_to_class.get(idx, f'class_{idx}')",
    "                    log_dict[f'fold{fold+1}/f1_{class_name}'] = f1",
    "            ",
    "            wandb.log(log_dict)",
    "        ",
    "        # Early Stopping ì²´í¬ ë° ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥",
    "        if val_f1 > best_f1 + Config.early_stopping_min_delta:",
    "            best_f1 = val_f1",
    "            patience_counter = 0",
    "            ",
    "            checkpoint = {",
    "                'fold': fold,",
    "                'epoch': epoch,",
    "                'model_state_dict': model.state_dict(),",
    "                'optimizer_state_dict': optimizer.state_dict(),",
    "                'best_f1': best_f1,",
    "            }",
    "            ",
    "            # ë¡œì»¬ì— ì €ì¥ (fold ë²ˆí˜¸ í¬í•¨)",
    "            local_model_path = f'best_model_aug_{Config.augmentation_level}_fold{fold+1}.pth'",
    "            torch.save(checkpoint, local_model_path)",
    "            print(f\"âœ“ Fold {fold+1} best model saved locally! (F1: {best_f1:.4f})\")",
    "            ",
    "            # êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥",
    "            if Config.save_to_drive:",
    "                if Config.use_wandb and Config.experiment_name:",
    "                    drive_model_path = f\"{Config.drive_model_dir}/{Config.experiment_name}_fold{fold+1}_f1_{best_f1:.4f}.pth\"",
    "                else:",
    "                    drive_model_path = f\"{Config.drive_model_dir}/best_model_aug_{Config.augmentation_level}_fold{fold+1}_f1_{best_f1:.4f}.pth\"",
    "                ",
    "                torch.save(checkpoint, drive_model_path)",
    "                if IS_COLAB:",
    "                    print(f\"âœ“ Fold {fold+1} best model saved to Google Drive: {drive_model_path}\")",
    "                else:",
    "                    print(f\"âœ“ Fold {fold+1} best model saved locally: {drive_model_path}\")",
    "            ",
    "            # WandBì— ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥",
    "            if Config.use_wandb:",
    "                artifact = wandb.Artifact(",
    "                    name=f'model-fold{fold+1}-{run.id}',",
    "                    type='model',",
    "                    description=f'Fold {fold+1} best model with F1: {best_f1:.4f}',",
    "                    metadata={",
    "                        'fold': fold + 1,",
    "                        'epoch': epoch + 1,",
    "                        'val_f1': val_f1,",
    "                        'val_loss': val_loss,",
    "                        'augmentation_level': Config.augmentation_level,",
    "                    }",
    "                )",
    "                artifact.add_file(local_model_path)",
    "                wandb.log_artifact(artifact)",
    "        else:",
    "            patience_counter += 1",
    "            print(f\"âš  No improvement. Patience: {patience_counter}/{Config.early_stopping_patience}\")",
    "            ",
    "            if patience_counter >= Config.early_stopping_patience:",
    "                print(f\"\\n{'='*60}\")",
    "                print(f\"Fold {fold+1} - Early Stopping triggered at epoch {epoch+1}\")",
    "                print(f\"Fold {fold+1} - Best Validation Macro F1: {best_f1:.4f}\")",
    "                print(f\"{'='*60}\")",
    "                break",
    "    ",
    "    # Fold ê²°ê³¼ ì €ì¥",
    "    fold_results.append({",
    "        'fold': fold + 1,",
    "        'best_f1': best_f1,",
    "        'history': history,",
    "        'final_epoch': epoch + 1",
    "    })",
    "    ",
    "    # ì „ì²´ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€",
    "    all_fold_history['train_loss'].extend(history['train_loss'])",
    "    all_fold_history['train_acc'].extend(history['train_acc'])",
    "    all_fold_history['val_loss'].extend(history['val_loss'])",
    "    all_fold_history['val_f1'].extend(history['val_f1'])",
    "    ",
    "    print(f\"\\n{'='*60}\")",
    "    print(f\"Fold {fold+1} completed!\")",
    "    print(f\"Fold {fold+1} - Best Validation Macro F1: {best_f1:.4f}\")",
    "    print(f\"Fold {fold+1} - Total epochs: {epoch+1}\")",
    "    print(f\"{'='*60}\\n\")",
    "",
    "# ì „ì²´ í•™ìŠµ ì™„ë£Œ í›„ ê²°ê³¼ ì¶œë ¥",
    "print(f\"\\n{'='*60}\")",
    "print(f\"3-Fold Cross Validation Training Completed!\")",
    "print(f\"{'='*60}\")",
    "for result in fold_results:",
    "    print(f\"Fold {result['fold']}: Best F1 = {result['best_f1']:.4f} (Epochs: {result['final_epoch']})\")",
    "",
    "avg_f1 = sum([r['best_f1'] for r in fold_results]) / len(fold_results)",
    "print(f\"\\nAverage F1 across folds: {avg_f1:.4f}\")",
    "print(f\"{'='*60}\")",
    "",
    "# ìµœì¢… ëª¨ë¸ ê²½ë¡œ ì¶œë ¥",
    "print(f\"\\nëª¨ë¸ ì €ì¥ ìœ„ì¹˜:\")",
    "for fold in range(n_splits):",
    "    print(f\"  - Fold {fold+1} ë¡œì»¬: best_model_aug_{Config.augmentation_level}_fold{fold+1}.pth\")",
    "if Config.save_to_drive:",
    "    print(f\"  - ë“œë¼ì´ë¸Œ: {Config.drive_model_dir}/\")",
    "",
    "# WandBì— ìµœì¢… ë©”íŠ¸ë¦­ ë¡œê¹…",
    "if Config.use_wandb:",
    "    wandb.log({",
    "        'final/avg_f1': avg_f1,",
    "        'final/best_fold': max(fold_results, key=lambda x: x['best_f1'])['fold'],",
    "        'final/best_f1': max([r['best_f1'] for r in fold_results]),",
    "    })",
    "    wandb.finish()",
    "",
    "# history ë³€ìˆ˜ë¥¼ all_fold_historyë¡œ ì„¤ì • (ì´í›„ ì‹œê°í™”ë¥¼ ìœ„í•´)",
    "history = all_fold_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt",
    "",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))",
    "",
    "# Loss ê·¸ë˜í”„",
    "axes[0].plot(history['train_loss'], label='Train Loss')",
    "axes[0].plot(history['val_loss'], label='Val Loss')",
    "axes[0].set_xlabel('Epoch')",
    "axes[0].set_ylabel('Loss')",
    "axes[0].set_title(f'Training and Validation Loss (Albumentations {Config.augmentation_level})')",
    "axes[0].legend()",
    "axes[0].grid(True)",
    "",
    "# F1 Score ê·¸ë˜í”„",
    "axes[1].plot(history['val_f1'], label='Val Macro F1', color='orange')",
    "axes[1].set_xlabel('Epoch')",
    "axes[1].set_ylabel('Macro F1 Score')",
    "axes[1].set_title(f'Validation Macro F1 Score (Albumentations {Config.augmentation_level})')",
    "axes[1].legend()",
    "axes[1].grid(True)",
    "",
    "plt.tight_layout()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ’¾ ì‹¤í—˜ ê²°ê³¼ ë°±ì—… (ë…¸íŠ¸ë¶ ì‚¬ë³¸ ì €ì¥)\n\ní•™ìŠµì´ ëë‚œ í›„ í˜„ì¬ ë…¸íŠ¸ë¶ì„ **ëª¨ë¸ëª…_F1ìŠ¤ì½”ì–´.ipynb** í˜•ì‹ìœ¼ë¡œ ìë™ ì €ì¥í•©ë‹ˆë‹¤.\n\n**ì €ì¥ ì˜ˆì‹œ:**\n- `efficientnet_b0_f1_0.8234.ipynb`\n- `efficientnet_b1_f1_0.8567.ipynb`\n- `convnext_tiny_f1_0.8892.ipynb`\n\n**ì¥ì :**\n- ê° ì‹¤í—˜ ê²°ê³¼ë¥¼ ì‰½ê²Œ ë¹„êµ\n- ë‚˜ì¤‘ì— ìµœê³  ì„±ëŠ¥ ë…¸íŠ¸ë¶ ì°¾ê¸° ì‰¬ì›€\n- ì‹¤í—˜ íˆìŠ¤í† ë¦¬ ìë™ ê´€ë¦¬"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil",
    "from datetime import datetime",
    "",
    "def save_notebook_with_score(model_name, f1_score, notebook_name='notebook.ipynb', ",
    "                             save_dir='./experiments'):",
    "    \"\"\"",
    "    í˜„ì¬ ë…¸íŠ¸ë¶ì„ ëª¨ë¸ëª…ê³¼ F1 ìŠ¤ì½”ì–´ë¥¼ í¬í•¨í•œ ì´ë¦„ìœ¼ë¡œ ì €ì¥",
    "    ",
    "    Args:",
    "        model_name: ëª¨ë¸ëª… (ì˜ˆ: 'efficientnet_b0')",
    "        f1_score: F1 ìŠ¤ì½”ì–´ (ì˜ˆ: 0.8234)",
    "        notebook_name: í˜„ì¬ ë…¸íŠ¸ë¶ íŒŒì¼ëª… (Colab: ìë™ ê°ì§€)",
    "        save_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬",
    "    ",
    "    Returns:",
    "        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ",
    "    \"\"\"",
    "    import os",
    "    ",
    "    # Colabì—ì„œ í˜„ì¬ ë…¸íŠ¸ë¶ ì´ë¦„ ìë™ ê°ì§€",
    "    try:",
    "        from google.colab import drive",
    "        # Colab í™˜ê²½ì—ì„œëŠ” ipynb íŒŒì¼ëª…ì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©",
    "        # ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•˜ê±°ë‚˜ ë§ˆìš´íŠ¸ëœ ë“œë¼ì´ë¸Œì—ì„œ í™•ì¸ í•„ìš”",
    "        pass",
    "    except:",
    "        pass",
    "    ",
    "    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±",
    "    os.makedirs(save_dir, exist_ok=True)",
    "    ",
    "    # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')",
    "    ",
    "    # ìƒˆ íŒŒì¼ëª… ìƒì„±",
    "    new_filename = f\"{model_name}_f1_{f1_score:.4f}_{timestamp}.ipynb\"",
    "    save_path = os.path.join(save_dir, new_filename)",
    "    ",
    "    # í˜„ì¬ ë…¸íŠ¸ë¶ ë³µì‚¬",
    "    try:",
    "        # Colab í™˜ê²½ì—ì„œëŠ” ì§ì ‘ ë³µì‚¬ê°€ ì–´ë ¤ìš°ë¯€ë¡œ ë“œë¼ì´ë¸Œì— ì €ì¥",
    "        if os.path.exists(notebook_name):",
    "            shutil.copy2(notebook_name, save_path)",
    "            print(f\"âœ“ ë…¸íŠ¸ë¶ ì €ì¥ ì™„ë£Œ: {save_path}\")",
    "        else:",
    "            # Colabì—ì„œëŠ” êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ìˆ˜ë™ ì €ì¥ ì•ˆë‚´",
    "            print(f\"\\n{'='*70}\")",
    "            print(\"Colab í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ ë°©ë²•ìœ¼ë¡œ ë…¸íŠ¸ë¶ì„ ì €ì¥í•˜ì„¸ìš”:\")",
    "            print(f\"{'='*70}\")",
    "            print(f\"1. ìƒë‹¨ ë©”ë‰´: íŒŒì¼ â†’ ë“œë¼ì´ë¸Œì— ì‚¬ë³¸ ì €ì¥\")",
    "            print(f\"2. íŒŒì¼ëª…ì„ ë‹¤ìŒê³¼ ê°™ì´ ë³€ê²½:\")",
    "            print(f\"   {new_filename}\")",
    "            print(f\"{'='*70}\\n\")",
    "            ",
    "            # êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ìë™ ì €ì¥ (ë§ˆìš´íŠ¸ë˜ì–´ ìˆëŠ” ê²½ìš°)",
    "            if Config.save_to_drive and os.path.exists('/content/drive'):",
    "                drive_notebook_dir = '/content/drive/MyDrive/document_classification/notebooks'",
    "                os.makedirs(drive_notebook_dir, exist_ok=True)",
    "                drive_path = os.path.join(drive_notebook_dir, new_filename)",
    "                ",
    "                print(f\"ğŸ’¡ ì¶”ì²œ ì €ì¥ ê²½ë¡œ:\")",
    "                print(f\"   {drive_path}\")",
    "                print(f\"\\n   â†’ ìœ„ ê²½ë¡œì— ìˆ˜ë™ìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”!\")",
    "                ",
    "                return drive_path",
    "    except Exception as e:",
    "        print(f\"âœ— ì €ì¥ ì‹¤íŒ¨: {e}\")",
    "        return None",
    "    ",
    "    return save_path",
    "",
    "",
    "def save_experiment_summary(model_name, f1_score, history, config_dict, ",
    "                           save_path='experiment_summary.txt'):",
    "    \"\"\"",
    "    ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥",
    "    ",
    "    Args:",
    "        model_name: ëª¨ë¸ëª…",
    "        f1_score: ìµœê³  F1 ìŠ¤ì½”ì–´",
    "        history: í•™ìŠµ íˆìŠ¤í† ë¦¬",
    "        config_dict: ì„¤ì • ì •ë³´ ë”•ì…”ë„ˆë¦¬",
    "        save_path: ì €ì¥ ê²½ë¡œ",
    "    \"\"\"",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')",
    "    ",
    "    summary = f\"\"\"",
    "{'='*70}",
    "ì‹¤í—˜ ê²°ê³¼ ìš”ì•½",
    "{'='*70}",
    "",
    "ì‹¤í—˜ ì¼ì‹œ: {timestamp}",
    "ëª¨ë¸ëª…: {model_name}",
    "ìµœê³  Validation F1: {f1_score:.4f}",
    "",
    "{'='*70}",
    "í•™ìŠµ ì„¤ì •",
    "{'='*70}",
    "\"\"\"",
    "    ",
    "    for key, value in config_dict.items():",
    "        summary += f\"{key}: {value}\\n\"",
    "    ",
    "    summary += f\"\"\"",
    "{'='*70}",
    "í•™ìŠµ íˆìŠ¤í† ë¦¬",
    "{'='*70}",
    "Epoch | Train Loss | Val Loss | Val F1",
    "------+------------+----------+--------",
    "\"\"\"",
    "    ",
    "    for i in range(len(history['train_loss'])):",
    "        summary += f\"{i+1:5d} | {history['train_loss'][i]:10.4f} | {history['val_loss'][i]:8.4f} | {history['val_f1'][i]:6.4f}\\n\"",
    "    ",
    "    summary += f\"\"\"",
    "{'='*70}",
    "ìµœì¢… ê²°ê³¼",
    "{'='*70}",
    "Best Validation F1: {f1_score:.4f}",
    "Total Epochs: {len(history['train_loss'])}",
    "Final Train Loss: {history['train_loss'][-1]:.4f}",
    "Final Val Loss: {history['val_loss'][-1]:.4f}",
    "{'='*70}",
    "\"\"\"",
    "    ",
    "    with open(save_path, 'w', encoding='utf-8') as f:",
    "        f.write(summary)",
    "    ",
    "    print(f\"âœ“ ì‹¤í—˜ ìš”ì•½ ì €ì¥: {save_path}\")",
    "    ",
    "    # êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ë„ ì €ì¥",
    "    if Config.save_to_drive and os.path.exists('/content/drive'):",
    "        drive_summary_dir = '/content/drive/MyDrive/document_classification/summaries'",
    "        os.makedirs(drive_summary_dir, exist_ok=True)",
    "        drive_summary_path = os.path.join(drive_summary_dir, ",
    "                                         f\"{model_name}_f1_{f1_score:.4f}_summary.txt\")",
    "        shutil.copy2(save_path, drive_summary_path)",
    "        print(f\"âœ“ êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ë„ ì €ì¥: {drive_summary_path}\")",
    "",
    "",
    "# í•™ìŠµ ì™„ë£Œ í›„ ìë™ ì €ì¥",
    "if 'best_f1' in locals() and 'history' in locals():",
    "    print(f\"\\n{'='*70}\")",
    "    print(\"ì‹¤í—˜ ê²°ê³¼ ìë™ ë°±ì—…\")",
    "    print(f\"{'='*70}\\n\")",
    "    ",
    "    # 1. ì‹¤í—˜ ìš”ì•½ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥",
    "    config_dict = {",
    "        'Model': Config.model_name,",
    "        'Image Size': Config.img_size,",
    "        'Batch Size': Config.batch_size,",
    "        'Learning Rate': Config.learning_rate,",
    "        'Epochs': Config.epochs,",
    "        'Augmentation': getattr(Config, 'augmentation_level', 'N/A'),",
    "    }",
    "    ",
    "    save_experiment_summary(",
    "        model_name=Config.model_name,",
    "        f1_score=best_f1,",
    "        history=history,",
    "        config_dict=config_dict,",
    "        save_path=f'{Config.model_name}_f1_{best_f1:.4f}_summary.txt'",
    "    )",
    "    ",
    "    # 2. ë…¸íŠ¸ë¶ ì‚¬ë³¸ ì €ì¥ ì•ˆë‚´",
    "    print(f\"\\nğŸ““ ë…¸íŠ¸ë¶ ì €ì¥ ì•ˆë‚´:\")",
    "    save_notebook_with_score(",
    "        model_name=Config.model_name,",
    "        f1_score=best_f1,",
    "        notebook_name='current_notebook.ipynb'  # Colabì—ì„œëŠ” ìë™ ê°ì§€ ë¶ˆê°€",
    "    )",
    "    ",
    "    print(f\"\\n{'='*70}\")",
    "    print(\"ë°±ì—… ì™„ë£Œ! ğŸ‰\")",
    "    print(f\"{'='*70}\")",
    "else:",
    "    print(\"âš ï¸ í•™ìŠµì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. í‹€ë¦° ì´ë¯¸ì§€ ë¶„ì„ (Error Analysis)\n\ní•™ìŠµì´ ëë‚œ í›„ validation setì—ì„œ í‹€ë¦¬ê²Œ ì˜ˆì¸¡í•œ ì´ë¯¸ì§€ë“¤ì„ í™•ì¸í•˜ì—¬ ëª¨ë¸ì˜ ì•½ì ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n**ë¶„ì„ ë‚´ìš©:**\n- ê°€ì¥ í™•ì‹ ìˆê²Œ í‹€ë¦° ì´ë¯¸ì§€ (ëª¨ë¸ì´ í™•ì‹ í–ˆëŠ”ë° í‹€ë¦° ê²½ìš°)\n- í´ë˜ìŠ¤ë³„ ì£¼ìš” ì˜¤ë¶„ë¥˜ íŒ¨í„´\n- ë‚®ì€ í™•ì‹ ë„ë¡œ ë§ì¶˜ ìƒ˜í”Œ (ë¶ˆí™•ì‹¤í•œ ê²½ìš°)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\ndef analyze_misclassified_images(model, val_dataset, val_paths, val_labels, class_to_idx, \n                                 device, num_samples=12, save_path=None):\n    \"\"\"\n    í‹€ë¦° ì´ë¯¸ì§€ë“¤ì„ ì‹œê°í™”í•˜ì—¬ ëª¨ë¸ì˜ ì•½ì  ë¶„ì„\n    \n    Args:\n        model: í•™ìŠµëœ ëª¨ë¸\n        val_dataset: Validation ë°ì´í„°ì…‹\n        val_paths: Validation ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n        val_labels: Validation ë¼ë²¨ ë¦¬ìŠ¤íŠ¸\n        class_to_idx: í´ë˜ìŠ¤ëª…-ì¸ë±ìŠ¤ ë§¤í•‘\n        device: ë””ë°”ì´ìŠ¤\n        num_samples: ì‹œê°í™”í•  ìƒ˜í”Œ ê°œìˆ˜\n        save_path: ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)\n    \"\"\"\n    model.eval()\n    idx_to_class = {v: k for k, v in class_to_idx.items()}\n    \n    # í‹€ë¦° ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘\n    misclassified = []\n    \n    with torch.no_grad():\n        for i in range(len(val_dataset)):\n            image, true_label = val_dataset[i]\n            image_tensor = image.unsqueeze(0).to(device)\n            \n            # ì˜ˆì¸¡\n            output = model(image_tensor)\n            _, predicted = output.max(1)\n            pred_label = predicted.item()\n            \n            # í‹€ë¦° ê²½ìš°ë§Œ ì €ì¥\n            if pred_label != true_label:\n                # í™•ë¥  ê³„ì‚°\n                probs = torch.softmax(output, dim=1)[0]\n                confidence = probs[pred_label].item()\n                true_confidence = probs[true_label].item()\n                \n                misclassified.append({\n                    'index': i,\n                    'path': val_paths[i],\n                    'true_label': true_label,\n                    'pred_label': pred_label,\n                    'true_class': idx_to_class[true_label],\n                    'pred_class': idx_to_class[pred_label],\n                    'confidence': confidence,\n                    'true_confidence': true_confidence\n                })\n    \n    # ê²°ê³¼ ì¶œë ¥\n    total_samples = len(val_dataset)\n    num_errors = len(misclassified)\n    accuracy = (total_samples - num_errors) / total_samples * 100\n    \n    print(f\"\\n{'='*70}\")\n    print(f\"Validation Set ì—ëŸ¬ ë¶„ì„\")\n    print(f\"{'='*70}\")\n    print(f\"ì „ì²´ ìƒ˜í”Œ: {total_samples}ê°œ\")\n    print(f\"í‹€ë¦° ìƒ˜í”Œ: {num_errors}ê°œ\")\n    print(f\"ì •í™•ë„: {accuracy:.2f}%\")\n    print(f\"{'='*70}\\n\")\n    \n    if num_errors == 0:\n        print(\"âœ“ ì™„ë²½! ëª¨ë“  ìƒ˜í”Œì„ ì •í™•íˆ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤!\")\n        return\n    \n    # í´ë˜ìŠ¤ë³„ ì—ëŸ¬ ë¶„ì„\n    class_errors = {}\n    for item in misclassified:\n        true_class = item['true_class']\n        pred_class = item['pred_class']\n        \n        if true_class not in class_errors:\n            class_errors[true_class] = {}\n        \n        if pred_class not in class_errors[true_class]:\n            class_errors[true_class][pred_class] = 0\n        \n        class_errors[true_class][pred_class] += 1\n    \n    print(\"ğŸ“Š í´ë˜ìŠ¤ë³„ ì£¼ìš” ì˜¤ë¶„ë¥˜:\")\n    print(f\"{'='*70}\")\n    for true_class in sorted(class_errors.keys()):\n        error_pairs = sorted(class_errors[true_class].items(), \n                           key=lambda x: x[1], reverse=True)\n        top_errors = error_pairs[:3]  # ìƒìœ„ 3ê°œë§Œ\n        \n        print(f\"\\n{true_class} (ì‹¤ì œ):\")\n        for pred_class, count in top_errors:\n            print(f\"  â†’ {pred_class} (ì˜ˆì¸¡): {count}íšŒ\")\n    print(f\"\\n{'='*70}\\n\")\n    \n    # ì‹œê°í™”í•  ìƒ˜í”Œ ì„ íƒ (confidenceê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ)\n    # confidenceê°€ ë†’ì€ë° í‹€ë¦° ê²½ìš° = ëª¨ë¸ì´ í™•ì‹ í–ˆëŠ”ë° í‹€ë¦° ì¼€ì´ìŠ¤\n    misclassified_sorted = sorted(misclassified, \n                                 key=lambda x: x['confidence'], \n                                 reverse=True)\n    \n    samples_to_show = min(num_samples, len(misclassified_sorted))\n    \n    # ê·¸ë¦¬ë“œ ë ˆì´ì•„ì›ƒ ê³„ì‚°\n    cols = 4\n    rows = (samples_to_show + cols - 1) // cols\n    \n    # ì‹œê°í™”\n    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n    if rows == 1:\n        axes = axes.reshape(1, -1)\n    \n    for idx in range(rows * cols):\n        row = idx // cols\n        col = idx % cols\n        ax = axes[row, col]\n        \n        if idx < samples_to_show:\n            item = misclassified_sorted[idx]\n            \n            # ì´ë¯¸ì§€ ë¡œë“œ\n            img = Image.open(item['path']).convert('RGB')\n            \n            # ì‹œê°í™”\n            ax.imshow(img)\n            \n            # ì œëª© ì„¤ì • (ì—¬ëŸ¬ ì¤„)\n            title = f\"ì‹¤ì œ: {item['true_class']}\\n\"\n            title += f\"ì˜ˆì¸¡: {item['pred_class']}\\n\"\n            title += f\"í™•ì‹ ë„: {item['confidence']:.1%}\"\n            \n            # ìƒ‰ìƒ ì„¤ì • (í™•ì‹ ë„ê°€ ë†’ì„ìˆ˜ë¡ ë¹¨ê°„ìƒ‰)\n            title_color = 'red' if item['confidence'] > 0.7 else 'orange'\n            \n            ax.set_title(title, fontsize=9, color=title_color, fontweight='bold')\n            ax.axis('off')\n        else:\n            ax.axis('off')\n    \n    plt.suptitle(f'ê°€ì¥ í™•ì‹ ìˆê²Œ í‹€ë¦° ì´ë¯¸ì§€ Top {samples_to_show}', \n                fontsize=16, fontweight='bold', y=0.995)\n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n        print(f\"âœ“ ë¶„ì„ ê²°ê³¼ ì €ì¥: {save_path}\")\n    \n    plt.show()\n    \n    # ì¶”ê°€ ë¶„ì„: ë‚®ì€ confidenceë¡œ ë§ì¶˜ ê²½ìš°\n    correct_low_conf = []\n    with torch.no_grad():\n        for i in range(len(val_dataset)):\n            image, true_label = val_dataset[i]\n            image_tensor = image.unsqueeze(0).to(device)\n            \n            output = model(image_tensor)\n            probs = torch.softmax(output, dim=1)[0]\n            _, predicted = output.max(1)\n            pred_label = predicted.item()\n            \n            if pred_label == true_label:\n                confidence = probs[pred_label].item()\n                if confidence < 0.6:  # í™•ì‹ ë„ê°€ ë‚®ì€ë° ë§ì¶˜ ê²½ìš°\n                    correct_low_conf.append({\n                        'index': i,\n                        'path': val_paths[i],\n                        'true_label': true_label,\n                        'true_class': idx_to_class[true_label],\n                        'confidence': confidence\n                    })\n    \n    if correct_low_conf:\n        print(f\"\\n{'='*70}\")\n        print(f\"âš ï¸ ë‚®ì€ í™•ì‹ ë„ë¡œ ë§ì¶˜ ìƒ˜í”Œ: {len(correct_low_conf)}ê°œ\")\n        print(f\"{'='*70}\")\n        print(\"ëª¨ë¸ì´ ë¶ˆí™•ì‹¤í•´í•˜ëŠ” ìƒ˜í”Œë“¤ì…ë‹ˆë‹¤. ì¶”ê°€ í•™ìŠµì´ë‚˜ ì¦ê°•ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\")\n\n\n# ì—ëŸ¬ ë¶„ì„ ì‹¤í–‰ (ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ í›„)\nif 'val_dataset' in locals() and 'val_paths' in locals():\n    print(\"\\nğŸ” Validation Set ì—ëŸ¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n    analyze_misclassified_images(\n        model=model,\n        val_dataset=val_dataset,\n        val_paths=val_paths,\n        val_labels=val_labels,\n        class_to_idx=class_to_idx,\n        device=device,\n        num_samples=12,  # 12ê°œ ìƒ˜í”Œ í‘œì‹œ\n        save_path='error_analysis.png'  # ê²°ê³¼ ì €ì¥\n    )\nelse:\n    print(\"âš ï¸ Validation ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 17. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ë¡ "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ",
    "def load_test_data(test_dir):",
    "    test_paths = []",
    "    for img_name in sorted(os.listdir(test_dir)):",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):",
    "            test_paths.append(os.path.join(test_dir, img_name))",
    "    return test_paths",
    "",
    "if os.path.exists(Config.test_dir):",
    "    test_paths = load_test_data(Config.test_dir)",
    "    print(f\"Total test images: {len(test_paths)}\")",
    "else:",
    "    print(f\"Warning: {Config.test_dir} does not exist!\")",
    "    test_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±",
    "if test_paths:",
    "    test_dataset = AugraphyDataset(test_paths, labels=None, transform=val_transform)",
    "    test_loader = DataLoader(",
    "        test_dataset, ",
    "        batch_size=Config.batch_size, ",
    "        shuffle=False, ",
    "        num_workers=Config.num_workers",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•™ìƒë¸” ì˜ˆì¸¡ (3ê°œ fold ëª¨ë¸ í‰ê· )",
    "print(f\"\\n{'='*60}\")",
    "print(\"Ensemble Prediction with 3 Fold Models\")",
    "print(f\"{'='*60}\\n\")",
    "",
    "# ëª¨ë“  fold ëª¨ë¸ ë¡œë“œ",
    "fold_models = []",
    "for fold in range(n_splits):",
    "    model_fold = DocumentClassifier(",
    "        model_name=Config.model_name,",
    "        num_classes=Config.num_classes,",
    "        pretrained=False",
    "    )",
    "    checkpoint_path = f\"best_model_aug_{Config.augmentation_level}_fold{fold+1}.pth\"",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)",
    "    model_fold.load_state_dict(checkpoint['model_state_dict'])",
    "    model_fold = model_fold.to(device)",
    "    model_fold.eval()",
    "    fold_models.append(model_fold)",
    "    print(f\"âœ“ Loaded fold {fold+1} model (F1: {checkpoint['best_f1']:.4f})\")",
    "",
    "# ì•™ìƒë¸” ì˜ˆì¸¡",
    "ensemble_preds = []",
    "with torch.no_grad():",
    "    for images in tqdm(test_loader, desc=\"Ensemble Inference\"):",
    "        if isinstance(images, tuple):",
    "            images = images[0]",
    "        images = images.to(device)",
    "        ",
    "        # ê° fold ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê· ",
    "        fold_outputs = []",
    "        for model_fold in fold_models:",
    "            outputs = model_fold(images)",
    "            fold_outputs.append(torch.softmax(outputs, dim=1))",
    "        ",
    "        # í‰ê·  ì˜ˆì¸¡",
    "        avg_output = torch.stack(fold_outputs).mean(dim=0)",
    "        preds = avg_output.argmax(dim=1)",
    "        ensemble_preds.extend(preds.cpu().numpy())",
    "",
    "print(f\"\\nâœ“ Ensemble prediction completed for {len(ensemble_preds)} test images\")",
    "",
    "# predictions ë³€ìˆ˜ë¥¼ ensemble_predsë¡œ ì—…ë°ì´íŠ¸",
    "predictions = ensemble_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 18. ì œì¶œ íŒŒì¼ ìƒì„±"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„± (í˜•ì‹ì€ ëŒ€íšŒ ê·œì •ì— ë§ê²Œ ìˆ˜ì •)",
    "if test_paths and predictions:",
    "    # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ë³€í™˜",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}",
    "    ",
    "    submission = pd.DataFrame({",
    "        'image': [os.path.basename(path) for path in test_paths],",
    "        'label': [idx_to_class[pred] for pred in predictions]",
    "    })",
    "    ",
    "    submission_filename = f'submission_aug_{Config.augmentation_level}.csv'",
    "    submission.to_csv(submission_filename, index=False)",
    "    print(f\"\\nSubmission file saved: {submission_filename}\")",
    "    print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 19. ê³ ê¸‰ íŒ ë° ì¶”ê°€ ê°œì„  ì•„ì´ë””ì–´\n\n### ğŸ”¬ ì»¤ìŠ¤í…€ ì¦ê°• ë§Œë“¤ê¸°\n\nê¸°ë³¸ ì œê³µë˜ëŠ” 3ê°€ì§€ ë ˆë²¨ ì™¸ì— ì§ì ‘ ì»¤ìŠ¤í…€ ì¦ê°•ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n```python\n# ì˜ˆì‹œ: ë¬¸ì„œ ìŠ¤ìº” íŠ¹í™” ì¦ê°•\ncustom_transform = A.Compose([\n    A.Resize(CFG.img_size, CFG.img_size),\n    \n    # ìŠ¤ìº” ì‹œ ë°œìƒí•˜ëŠ” ë…¸ì´ì¦ˆ\n    A.OneOf([\n        A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n        A.ISONoise(p=1.0),\n    ], p=0.3),\n    \n    # êµ¬ê²¨ì§„ ë¬¸ì„œ íš¨ê³¼\n    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n    \n    # íŒ©ìŠ¤/ë³µì‚¬ê¸° ë¸”ëŸ¬\n    A.Blur(blur_limit=3, p=0.2),\n    \n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2()\n])\n```\n\n---\n\n### ğŸ¯ Test Time Augmentation (TTA)\n\nì¶”ë¡  ì‹œì—ë„ ì¦ê°•ì„ ì ìš©í•˜ì—¬ **ì•™ìƒë¸” íš¨ê³¼**ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n```python\ndef predict_with_tta(model, image, transforms, n_augmentations=5):\n    \"\"\"\n    TTAë¥¼ ì ìš©í•œ ì˜ˆì¸¡ í•¨ìˆ˜\n    ê°™ì€ ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ë²ˆ ì¦ê°•í•˜ê³  ì˜ˆì¸¡ì„ í‰ê· ë‚´ì–´ ë” ì•ˆì •ì ì¸ ê²°ê³¼ íšë“\n    \"\"\"\n    model.eval()\n    predictions = []\n    \n    with torch.no_grad():\n        for _ in range(n_augmentations):\n            augmented = transforms(image=image)\n            img_tensor = augmented['image'].unsqueeze(0).to(device)\n            output = model(img_tensor)\n            predictions.append(output.softmax(dim=1))\n    \n    # í‰ê·  ì˜ˆì¸¡\n    avg_prediction = torch.stack(predictions).mean(dim=0)\n    return avg_prediction.argmax(dim=1).item()\n```\n\n**TTA ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­:**\n- ì¶”ë¡  ì‹œê°„ì´ n_augmentationsë°° ì¦ê°€\n- ì¼ë°˜ì ìœ¼ë¡œ 0.5-2% ì„±ëŠ¥ í–¥ìƒ\n- ìµœì¢… ì œì¶œ ì‹œì—ë§Œ ì‚¬ìš© ê¶Œì¥\n\n---\n\n### ğŸ“ˆ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¶”ê°€ ì•„ì´ë””ì–´\n\n#### 1. **ì¦ê°• íŒŒë¼ë¯¸í„° íŠœë‹**\n```python\n# WandB Sweepìœ¼ë¡œ ìµœì  ì¦ê°• ê°•ë„ ì°¾ê¸°\nsweep_config = {\n    'method': 'bayes',\n    'parameters': {\n        'augmentation_level': {\n            'values': ['light', 'medium', 'heavy']\n        },\n        'learning_rate': {\n            'min': 1e-5,\n            'max': 1e-3\n        }\n    }\n}\n```\n\n#### 2. **MixUp / CutMix**\n```python\n# Augraphyì˜ MixUp transform\nA.MixUp(alpha=0.2, p=0.5)\n```\n\n#### 3. **í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì¦ê°•**\n```python\n# ë¶ˆê· í˜• ë°ì´í„°ì…‹ì˜ ê²½ìš° ì†Œìˆ˜ í´ë˜ìŠ¤ì— ë” ê°•í•œ ì¦ê°• ì ìš©\nif label in minority_classes:\n    transform = heavy_transform\nelse:\n    transform = medium_transform\n```\n\n#### 4. **AutoAugment / RandAugment**\n```python\n# ìë™ìœ¼ë¡œ ìµœì  ì¦ê°• ì •ì±… í•™ìŠµ\nfrom augraphy.pytorch import ToTensorV2\n# Augraphyë„ AutoAugment ì§€ì›\n```\n\n---\n\n### ğŸ” ë””ë²„ê¹… íŒ\n\n**ì¦ê°•ì´ ë„ˆë¬´ ê°•í•´ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤ë©´:**\n1. ì„¹ì…˜ 9ì˜ ì‹œê°í™”ë¡œ ì¦ê°• ê²°ê³¼ í™•ì¸\n2. `p` (í™•ë¥ ) íŒŒë¼ë¯¸í„° ì¡°ì •\n3. ë” ì•½í•œ ë ˆë²¨ë¡œ ë³€ê²½\n\n**í•™ìŠµì´ ë¶ˆì•ˆì •í•˜ë‹¤ë©´:**\n1. Learning rate ê°ì†Œ\n2. Batch size ì¦ê°€\n3. ì¦ê°• ê°•ë„ ê°ì†Œ\n\n---\n\n### ğŸ“š ì°¸ê³  ìë£Œ\n\n- [Augraphy ê³µì‹ ë¬¸ì„œ](https://augraphy.ai/docs/)\n- [Augraphy ì˜ˆì œ ëª¨ìŒ](https://augraphy.ai/docs/examples/)\n- [ë¬¸ì„œ ì´ë¯¸ì§€ ì¦ê°• Best Practices](https://arxiv.org/abs/2106.08322)\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}