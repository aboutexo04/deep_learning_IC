{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 이미지 분류 베이스라인\n",
    "\n",
    "## 대회 정보\n",
    "- **Task**: 문서 이미지 분류 (건강보험증, 여권 등)\n",
    "- **Train Data**: ~1,500장 | **Test Data**: ~3,000장\n",
    "- **Metric**: Macro F1 Score | **Framework**: PyTorch\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 추천 모델 (실험 순서)\n",
    "\n",
    "### 1단계: Baseline ⭐⭐⭐⭐⭐\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b0'\n",
    "```\n",
    "**파라미터**: 5M | **속도**: ~1분/epoch | **용도**: 가장 가볍고 빠른 시작점\n",
    "\n",
    "### 2단계: 성능 향상 ⭐⭐⭐⭐⭐\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b1'  # 추천 1순위\n",
    "# 또는\n",
    "CFG.model_name = 'efficientnet_b2'  # 추천 2순위\n",
    "```\n",
    "**B1**: 7M, ~1.5분/epoch, B0 대비 +2~3% 향상  \n",
    "**B2**: 9M, ~2분/epoch, B0 대비 +3~5% 향상\n",
    "\n",
    "### 3단계: 최신 아키텍처 ⭐⭐⭐⭐⭐\n",
    "```python\n",
    "CFG.model_name = 'convnext_tiny'\n",
    "```\n",
    "**파라미터**: 28M | **속도**: ~2.5분/epoch | **특징**: 최신(2022), B0 대비 +5~7% 향상\n",
    "\n",
    "### 4단계: 성능 극대화 ⭐⭐⭐⭐\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b3'  # 1순위\n",
    "# 또는\n",
    "CFG.model_name = 'convnext_small'   # 2순위 (최고 성능)\n",
    "```\n",
    "**B3**: 12M, ~2.5분/epoch, B0 대비 +5~8% 향상  \n",
    "**ConvNeXt-Small**: 50M, ~4분/epoch, B0 대비 +7~10% 향상\n",
    "\n",
    "### 5단계: Transformer (선택) ⭐⭐\n",
    "```python\n",
    "CFG.model_name = 'vit_base_patch16_224'\n",
    "# 또는\n",
    "CFG.model_name = 'swin_base_patch4_window7_224'\n",
    "```\n",
    "**ViT**: 86M, ~5분/epoch | **Swin**: 88M, ~5분/epoch  \n",
    "**주의**: 1,500장에선 과적합 위험 높음, 강한 증강 필요, **비추천**\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 비추천 모델\n",
    "- `resnet50` / `resnet101` - EfficientNet보다 비효율적\n",
    "- `mobilenetv3_large_100` - 속도 빠르지만 성능 낮음\n",
    "- `vit` / `swin` - 데이터 부족 시 과적합 (10,000장 이상일 때 추천)\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 실험 시나리오\n",
    "\n",
    "### 시나리오 1: 빠른 실험 (2시간)\n",
    "1. B0 + medium 증강 → 30분\n",
    "2. B0 + light 증강 → 30분\n",
    "3. B0 + heavy 증강 → 30분\n",
    "4. B1 + 최고 증강 → 40분\n",
    "\n",
    "### 시나리오 2: 균형 실험 (4시간)\n",
    "B0(3가지 증강) → B1 → B2 → ConvNeXt-Tiny → 최고 모델 재학습\n",
    "\n",
    "### 시나리오 3: 최고 성능 (하루)\n",
    "B0 최적화 → B1/B2 → ConvNeXt-Tiny → B3 → ConvNeXt-Small → 앙상블\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 트러블슈팅\n",
    "\n",
    "**GPU 메모리 부족**: `batch_size = 16` 또는 `img_size = 192`  \n",
    "**학습 느림**: `epochs = 20` (EfficientNet-B0/B1은 20 epoch 충분)  \n",
    "**성능 plateau**: 모델 크기보다 증강/하이퍼파라미터 튜닝 먼저!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install timm wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import wandb\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시드 고정 (재현성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 구글 드라이브 마운트 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 드라이브 마운트 (데이터나 모델을 드라이브에 저장하려면 실행)\n",
    "# 실행하면 인증 링크가 나타나고, 권한 승인 후 코드를 붙여넣으면 됩니다.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"구글 드라이브가 /content/drive 에 마운트되었습니다.\")\n",
    "print(\"데이터 경로 예시: /content/drive/MyDrive/your_data_folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. WandB 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB 로그인 (처음 실행시 API 키 입력 필요)\n",
    "# https://wandb.ai/authorize 에서 API 키 발급\n",
    "wandb.login()\n",
    "\n",
    "# 프로젝트명은 실제 대회명으로 변경하세요\n",
    "WANDB_PROJECT = \"document-classification\"\n",
    "WANDB_ENTITY = None  # 팀 계정 사용시 팀명 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 모델별 권장 이미지 사이즈 (문서 이미지 최적화)\n# 문서 이미지는 텍스트와 세밀한 디테일이 중요하므로 일반 이미지보다 큰 사이즈 사용\nMODEL_IMG_SIZES = {\n    'efficientnet_b0': 384,   # 기본 224 → 384로 증가\n    'efficientnet_b1': 416,   # 기본 240 → 416으로 증가\n    'efficientnet_b2': 448,   # 기본 260 → 448로 증가\n    'efficientnet_b3': 512,   # 기본 300 → 512로 증가\n    'efficientnet_b4': 512,   # 기본 380 → 512 유지\n    'convnext_tiny': 384,     # 기본 224 → 384로 증가\n    'convnext_small': 384,    # 기본 224 → 384로 증가\n    'vit_base_patch16_224': 384,  # 기본 224 → 384로 증가\n    'swin_base_patch4_window7_224': 384,  # 기본 224 → 384로 증가\n}\n\nclass CFG:\n    # 데이터 경로\n    train_dir = './data/train'  # 학습 이미지 폴더\n    test_dir = './data/test'    # 테스트 이미지 폴더\n    \n    # 모델 설정\n    model_name = 'efficientnet_b0'  # timm 모델명\n    num_classes = 10  # 실제 클래스 개수로 변경 필요\n    img_size = MODEL_IMG_SIZES.get(model_name, 384)  # 모델별 권장 사이즈 자동 적용 (문서 이미지용)\n    \n    # 학습 설정\n    epochs = 30\n    batch_size = 32\n    learning_rate = 1e-4\n    weight_decay = 1e-5\n    \n    # Early Stopping 설정\n    early_stopping_patience = 3  # 3 epoch 동안 개선 없으면 중단\n    early_stopping_min_delta = 0.0001  # F1 차이 0.01% 미만은 개선 아님\n    \n    # 데이터 분할\n    val_ratio = 0.2\n    \n    # 모델 저장 경로\n    save_to_drive = True  # 구글 드라이브에 저장 여부\n    drive_model_dir = '/content/drive/MyDrive/document_classification/models'  # 드라이브 저장 경로\n    local_model_path = 'best_model.pth'  # 로컬 저장 경로\n    \n    # WandB 설정\n    use_wandb = True\n    wandb_project = WANDB_PROJECT\n    wandb_entity = WANDB_ENTITY\n    experiment_name = None  # None이면 자동으로 번호 부여\n    \n    # 실험명 접두사 설정\n    # 옵션 1: 모델명 자동 사용 (기본, None으로 두면 자동)\n    experiment_prefix = None  # None이면 model_name 사용\n    \n    # 옵션 2: 커스텀 prefix 사용 (필요시 아래 주석 해제)\n    # experiment_prefix = 'baseline'  # baseline_001, baseline_002 ...\n    # experiment_prefix = 'augment'   # augment_001, augment_002 ...\n    \n    # 기타\n    num_workers = 2\n    seed = 42"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 데이터 증강 (Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 Transform\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG.img_size, CFG.img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 검증/테스트용 Transform\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CFG.img_size, CFG.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 데이터 로드 및 전처리\n",
    "\n",
    "**주의**: 데이터 폴더 구조에 맞게 수정이 필요합니다.\n",
    "\n",
    "예상 구조:\n",
    "```\n",
    "data/\n",
    "├── train/\n",
    "│   ├── class1/\n",
    "│   ├── class2/\n",
    "│   └── ...\n",
    "└── test/\n",
    "    ├── image1.jpg\n",
    "    ├── image2.jpg\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "또는 CSV 파일이 있다면:\n",
    "```python\n",
    "train_df = pd.read_csv('train.csv')\n",
    "# train_df: ['image_path', 'label'] 컬럼 포함\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: 폴더 구조로부터 데이터 로드\n",
    "def load_data_from_folders(data_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_name in os.listdir(class_dir):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(class_to_idx[class_name])\n",
    "    \n",
    "    return image_paths, labels, class_to_idx\n",
    "\n",
    "# 학습 데이터 로드\n",
    "if os.path.exists(CFG.train_dir):\n",
    "    train_paths, train_labels, class_to_idx = load_data_from_folders(CFG.train_dir)\n",
    "    print(f\"Total training images: {len(train_paths)}\")\n",
    "    print(f\"Number of classes: {len(class_to_idx)}\")\n",
    "    print(f\"Classes: {class_to_idx}\")\n",
    "    \n",
    "    # CFG.num_classes 업데이트\n",
    "    CFG.num_classes = len(class_to_idx)\n",
    "else:\n",
    "    print(f\"Warning: {CFG.train_dir} does not exist!\")\n",
    "    print(\"Please upload your data or modify the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2: CSV 파일로부터 데이터 로드 (필요시 사용)\n",
    "# train_df = pd.read_csv('train.csv')\n",
    "# train_paths = train_df['image_path'].tolist()\n",
    "# train_labels = train_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation 분할\n",
    "if 'train_paths' in locals():\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_paths, train_labels, \n",
    "        test_size=CFG.val_ratio, \n",
    "        random_state=CFG.seed,\n",
    "        stratify=train_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Train size: {len(train_paths)}\")\n",
    "    print(f\"Validation size: {len(val_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 및 데이터로더 생성\n",
    "if 'train_paths' in locals():\n",
    "    train_dataset = DocumentDataset(train_paths, train_labels, train_transform)\n",
    "    val_dataset = DocumentDataset(val_paths, val_labels, val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=CFG.num_workers\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=CFG.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. WandB Run 초기화 (학습 시작 전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_experiment_number(project_name, prefix, entity=None):\n",
    "    \"\"\"WandB에서 기존 실험들을 확인하고 다음 번호를 반환\"\"\"\n",
    "    try:\n",
    "        api = wandb.Api()\n",
    "        # 프로젝트의 모든 run 가져오기\n",
    "        if entity:\n",
    "            runs = api.runs(f\"{entity}/{project_name}\")\n",
    "        else:\n",
    "            runs = api.runs(project_name)\n",
    "        \n",
    "        # prefix로 시작하는 run들의 번호 추출\n",
    "        numbers = []\n",
    "        for run in runs:\n",
    "            if run.name.startswith(prefix):\n",
    "                try:\n",
    "                    # 'prefix_123' 형태에서 123 추출\n",
    "                    num = int(run.name.split('_')[-1])\n",
    "                    numbers.append(num)\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # 가장 큰 번호 + 1 반환\n",
    "        next_num = max(numbers) + 1 if numbers else 1\n",
    "        return next_num\n",
    "    except:\n",
    "        # API 접근 실패시 001부터 시작\n",
    "        return 1\n",
    "\n",
    "# WandB Run 초기화\n",
    "if CFG.use_wandb:\n",
    "    # experiment_prefix가 None이면 모델명 사용 (자동)\n",
    "    if CFG.experiment_prefix is None:\n",
    "        actual_prefix = CFG.model_name\n",
    "    else:\n",
    "        actual_prefix = CFG.experiment_prefix\n",
    "    \n",
    "    # 실험명 자동 생성\n",
    "    if CFG.experiment_name is None:\n",
    "        exp_num = get_next_experiment_number(\n",
    "            CFG.wandb_project, \n",
    "            actual_prefix,\n",
    "            CFG.wandb_entity\n",
    "        )\n",
    "        CFG.experiment_name = f\"{actual_prefix}_{exp_num:03d}\"\n",
    "    \n",
    "    run = wandb.init(\n",
    "        project=CFG.wandb_project,\n",
    "        entity=CFG.wandb_entity,\n",
    "        name=CFG.experiment_name,\n",
    "        config={\n",
    "            \"model_name\": CFG.model_name,\n",
    "            \"num_classes\": CFG.num_classes,\n",
    "            \"img_size\": CFG.img_size,\n",
    "            \"epochs\": CFG.epochs,\n",
    "            \"batch_size\": CFG.batch_size,\n",
    "            \"learning_rate\": CFG.learning_rate,\n",
    "            \"weight_decay\": CFG.weight_decay,\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"scheduler\": \"CosineAnnealingLR\",\n",
    "            \"val_ratio\": CFG.val_ratio,\n",
    "            \"seed\": CFG.seed,\n",
    "        }\n",
    "    )\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"WandB Run initialized: {run.name}\")\n",
    "    print(f\"WandB URL: {run.url}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    print(\"WandB is disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, pretrained=True):\n",
    "        super(DocumentClassifier, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        \n",
    "        # 모델의 classifier 부분 수정\n",
    "        if 'efficientnet' in model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(in_features, num_classes)\n",
    "        elif 'resnet' in model_name:\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features, num_classes)\n",
    "        elif 'vit' in model_name:\n",
    "            in_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 모델 생성\n",
    "model = DocumentClassifier(\n",
    "    model_name=CFG.model_name, \n",
    "    num_classes=CFG.num_classes, \n",
    "    pretrained=True\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model: {CFG.model_name}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# WandB에 모델 아키텍처 로깅\n",
    "if CFG.use_wandb:\n",
    "    wandb.watch(model, log='all', log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 손실 함수 및 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CFG.learning_rate, weight_decay=CFG.weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 학습 및 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # 배치별 메트릭 계산\n",
    "        batch_loss = running_loss / (batch_idx + 1)\n",
    "        batch_acc = 100. * correct / total\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': batch_loss,\n",
    "            'acc': batch_acc\n",
    "        })\n",
    "        \n",
    "        # WandB 로깅 (매 배치마다)\n",
    "        if CFG.use_wandb:\n",
    "            wandb.log({\n",
    "                'train/batch_loss': loss.item(),\n",
    "                'train/batch_acc': 100. * predicted.eq(labels).sum().item() / labels.size(0),\n",
    "                'train/step': epoch * len(train_loader) + batch_idx\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    \n",
    "    # Macro F1 Score 계산\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # 클래스별 F1 Score 계산\n",
    "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
    "    \n",
    "    # Confusion Matrix 계산\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, macro_f1, per_class_f1, cm, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_f1 = 0.0\npatience_counter = 0  # Early Stopping 카운터\nhistory = {\n    'train_loss': [],\n    'train_acc': [],\n    'val_loss': [],\n    'val_f1': []\n}\n\n# 구글 드라이브 저장 경로 생성\nif CFG.save_to_drive:\n    os.makedirs(CFG.drive_model_dir, exist_ok=True)\n    print(f\"모델 저장 경로: {CFG.drive_model_dir}\")\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Early Stopping: Patience={CFG.early_stopping_patience}, Min Delta={CFG.early_stopping_min_delta}\")\nprint(f\"{'='*60}\\n\")\n\nfor epoch in range(CFG.epochs):\n    print(f\"\\nEpoch {epoch+1}/{CFG.epochs}\")\n    print(\"-\" * 50)\n    \n    # 학습\n    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)\n    \n    # 검증\n    val_loss, val_f1, per_class_f1, cm, val_preds, val_labels = validate(model, val_loader, criterion, device)\n    \n    # 스케줄러 업데이트\n    scheduler.step()\n    current_lr = optimizer.param_groups[0]['lr']\n    \n    # 결과 저장\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_f1'].append(val_f1)\n    \n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Macro F1: {val_f1:.4f}\")\n    print(f\"Learning Rate: {current_lr:.6f}\")\n    \n    # WandB 로깅 (에폭별)\n    if CFG.use_wandb:\n        # 기본 메트릭\n        log_dict = {\n            'epoch': epoch + 1,\n            'train/epoch_loss': train_loss,\n            'train/epoch_acc': train_acc,\n            'val/loss': val_loss,\n            'val/macro_f1': val_f1,\n            'learning_rate': current_lr,\n            'early_stopping/patience_counter': patience_counter,\n        }\n        \n        # 클래스별 F1 Score\n        if 'class_to_idx' in locals():\n            idx_to_class = {v: k for k, v in class_to_idx.items()}\n            for idx, f1 in enumerate(per_class_f1):\n                class_name = idx_to_class.get(idx, f'class_{idx}')\n                log_dict[f'val/f1_{class_name}'] = f1\n        \n        # Confusion Matrix (5 에폭마다)\n        if (epoch + 1) % 5 == 0:\n            log_dict['val/confusion_matrix'] = wandb.plot.confusion_matrix(\n                probs=None,\n                y_true=val_labels,\n                preds=val_preds,\n                class_names=[idx_to_class.get(i, f'class_{i}') for i in range(CFG.num_classes)] if 'idx_to_class' in locals() else None\n            )\n        \n        wandb.log(log_dict)\n    \n    # Early Stopping 체크 및 베스트 모델 저장\n    if val_f1 > best_f1 + CFG.early_stopping_min_delta:\n        # 성능 개선됨\n        best_f1 = val_f1\n        patience_counter = 0  # 카운터 리셋\n        \n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_f1': best_f1,\n        }\n        \n        # 로컬에 저장\n        torch.save(checkpoint, CFG.local_model_path)\n        print(f\"✓ Best model saved locally! (F1: {best_f1:.4f})\")\n        \n        # 구글 드라이브에 저장\n        if CFG.save_to_drive:\n            # 실험명을 파일명에 포함\n            if CFG.use_wandb and CFG.experiment_name:\n                drive_model_path = f\"{CFG.drive_model_dir}/{CFG.experiment_name}_f1_{best_f1:.4f}.pth\"\n            else:\n                drive_model_path = f\"{CFG.drive_model_dir}/best_model_f1_{best_f1:.4f}.pth\"\n            \n            torch.save(checkpoint, drive_model_path)\n            print(f\"✓ Best model saved to drive: {drive_model_path}\")\n        \n        # WandB에 베스트 모델 저장\n        if CFG.use_wandb:\n            artifact = wandb.Artifact(\n                name=f'model-{run.id}',\n                type='model',\n                description=f'Best model with F1: {best_f1:.4f}',\n                metadata={\n                    'epoch': epoch + 1,\n                    'val_f1': val_f1,\n                    'val_loss': val_loss,\n                }\n            )\n            artifact.add_file(CFG.local_model_path)\n            wandb.log_artifact(artifact)\n    else:\n        # 성능 개선 없음\n        patience_counter += 1\n        print(f\"⚠ No improvement. Patience: {patience_counter}/{CFG.early_stopping_patience}\")\n        \n        # Early Stopping 체크\n        if patience_counter >= CFG.early_stopping_patience:\n            print(f\"\\n{'='*60}\")\n            print(f\"Early Stopping triggered at epoch {epoch+1}\")\n            print(f\"Best Validation Macro F1: {best_f1:.4f}\")\n            print(f\"{'='*60}\")\n            break\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Training completed!\")\nprint(f\"Best Validation Macro F1: {best_f1:.4f}\")\nprint(f\"Total epochs: {epoch+1}\")\nif patience_counter >= CFG.early_stopping_patience:\n    print(f\"Stopped early due to no improvement for {CFG.early_stopping_patience} epochs\")\nprint(f\"{'='*50}\")\n\n# 최종 모델 경로 출력\nprint(f\"\\n모델 저장 위치:\")\nprint(f\"  - 로컬: {CFG.local_model_path}\")\nif CFG.save_to_drive:\n    print(f\"  - 드라이브: {CFG.drive_model_dir}/\")\n\n# WandB Run 종료\nif CFG.use_wandb:\n    wandb.finish()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss 그래프\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# F1 Score 그래프\n",
    "axes[1].plot(history['val_f1'], label='Val Macro F1', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Macro F1 Score')\n",
    "axes[1].set_title('Validation Macro F1 Score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 테스트 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 모델 로드\n",
    "checkpoint = torch.load('best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model loaded (F1: {checkpoint['best_f1']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로드\n",
    "def load_test_data(test_dir):\n",
    "    test_paths = []\n",
    "    for img_name in sorted(os.listdir(test_dir)):\n",
    "        if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            test_paths.append(os.path.join(test_dir, img_name))\n",
    "    return test_paths\n",
    "\n",
    "if os.path.exists(CFG.test_dir):\n",
    "    test_paths = load_test_data(CFG.test_dir)\n",
    "    print(f\"Total test images: {len(test_paths)}\")\n",
    "else:\n",
    "    print(f\"Warning: {CFG.test_dir} does not exist!\")\n",
    "    test_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 및 로더 생성\n",
    "if test_paths:\n",
    "    test_dataset = DocumentDataset(test_paths, labels=None, transform=val_transform)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=CFG.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=CFG.num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 함수\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader, desc='Predicting'):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 추론 실행\n",
    "if test_paths:\n",
    "    predictions = predict(model, test_loader, device)\n",
    "    print(f\"Prediction completed: {len(predictions)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 생성 (형식은 대회 규정에 맞게 수정)\n",
    "if test_paths and predictions:\n",
    "    # 클래스 인덱스를 클래스 이름으로 변환\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'image': [os.path.basename(path) for path in test_paths],\n",
    "        'label': [idx_to_class[pred] for pred in predictions]\n",
    "    })\n",
    "    \n",
    "    # 또는 숫자 레이블로 제출하는 경우:\n",
    "    # submission = pd.DataFrame({\n",
    "    #     'image': [os.path.basename(path) for path in test_paths],\n",
    "    #     'label': predictions\n",
    "    # })\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"\\nSubmission file saved: submission.csv\")\n",
    "    print(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 추가 개선 아이디어\n",
    "\n",
    "### 모델 개선\n",
    "1. **다양한 모델 시도**\n",
    "   - `efficientnet_b3`, `efficientnet_b4` (더 큰 모델)\n",
    "   - `convnext_tiny`, `convnext_small`\n",
    "   - `vit_base_patch16_224` (Vision Transformer)\n",
    "   - `swin_base_patch4_window7_224`\n",
    "\n",
    "2. **앙상블**\n",
    "   - 여러 모델의 예측을 결합 (Voting, Averaging)\n",
    "   - K-Fold Cross Validation\n",
    "\n",
    "3. **데이터 증강 강화**\n",
    "   - AutoAugment, RandAugment\n",
    "   - MixUp, CutMix\n",
    "   - Test Time Augmentation (TTA)\n",
    "\n",
    "4. **학습 기법**\n",
    "   - Label Smoothing\n",
    "   - Focal Loss (클래스 불균형 시)\n",
    "   - Stochastic Weight Averaging (SWA)\n",
    "   - Gradient Accumulation (배치 크기 확장)\n",
    "\n",
    "5. **이미지 전처리**\n",
    "   - 문서 정렬 (Document alignment)\n",
    "   - 해상도 조정\n",
    "   - 노이즈 제거\n",
    "\n",
    "### WandB 활용 팁\n",
    "1. **Sweep을 이용한 하이퍼파라미터 튜닝**\n",
    "   - 자동으로 최적의 하이퍼파라미터 찾기\n",
    "   - Bayesian Optimization, Random Search 등 지원\n",
    "\n",
    "2. **실험 비교**\n",
    "   - 여러 실험을 한눈에 비교\n",
    "   - Parallel coordinates plot으로 관계 분석\n",
    "\n",
    "3. **팀 협업**\n",
    "   - 팀원과 실험 결과 공유\n",
    "   - 코멘트 및 노트 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코랩 환경 팁\n",
    "\n",
    "### 1. GPU 런타임 사용\n",
    "상단 메뉴: `런타임` → `런타임 유형 변경` → `하드웨어 가속기: GPU`\n",
    "\n",
    "### 2. 구글 드라이브 마운트\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "\n",
    "### 3. 데이터 업로드\n",
    "- 좌측 파일 탭에서 업로드\n",
    "- 또는 구글 드라이브에서 읽기\n",
    "- Kaggle API 사용 (Kaggle 대회인 경우)\n",
    "\n",
    "### 4. 모델 및 결과 저장\n",
    "```python\n",
    "# 구글 드라이브에 저장\n",
    "torch.save(model.state_dict(), '/content/drive/MyDrive/models/best_model.pth')\n",
    "```\n",
    "\n",
    "### 5. WandB 실험명 자동 번호 부여 사용법 (중요!)\n",
    "\n",
    "#### 📌 기본 개념\n",
    "이 노트북은 **실험명을 자동으로 번호를 매겨서 관리**하는 기능이 내장되어 있습니다.\n",
    "**기본 설정: 모델명만 바꾸면 자동으로 실험명도 변경됩니다!** ⭐\n",
    "\n",
    "#### ✨ 사용법 (매우 간단!)\n",
    "\n",
    "**모델만 바꾸면 끝!**\n",
    "```python\n",
    "# 섹션 4의 CFG 클래스에서\n",
    "CFG.model_name = 'efficientnet_b0'  # ← 이것만 바꾸면 됩니다!\n",
    "```\n",
    "→ 자동으로 `efficientnet_b0_001`, `efficientnet_b0_002` ...\n",
    "\n",
    "**다른 모델로 실험하고 싶다면?**\n",
    "```python\n",
    "CFG.model_name = 'resnet50'  # ← 모델명만 변경\n",
    "```\n",
    "→ 자동으로 `resnet50_001`, `resnet50_002` ...\n",
    "\n",
    "그게 다입니다! 나머지는 자동으로 처리됩니다. 😊\n",
    "\n",
    "#### 🔧 상세 설정 (선택사항)\n",
    "\n",
    "**방법 1: 모델명 자동 사용 (기본값, 권장) ⭐**\n",
    "```python\n",
    "# 섹션 4의 CFG 클래스에서\n",
    "CFG.model_name = 'efficientnet_b0'\n",
    "CFG.experiment_prefix = None  # None으로 유지 (기본값)\n",
    "CFG.experiment_name = None    # None으로 유지 (기본값)\n",
    "```\n",
    "→ 결과: `efficientnet_b0_001`, `efficientnet_b0_002` ...\n",
    "\n",
    "**방법 2: 커스텀 prefix 사용**\n",
    "```python\n",
    "# 모델명 대신 다른 이름을 사용하고 싶을 때\n",
    "CFG.experiment_prefix = 'baseline'\n",
    "```\n",
    "→ 결과: `baseline_001`, `baseline_002` ...\n",
    "\n",
    "**방법 3: 완전히 수동으로 실험명 지정**\n",
    "```python\n",
    "# 특정 실험에 의미있는 이름을 붙이고 싶을 때\n",
    "CFG.experiment_name = 'final_submission_v1'\n",
    "```\n",
    "→ 결과: `final_submission_v1` (지정한 이름 그대로)\n",
    "\n",
    "#### 💡 실험 시나리오별 활용 예시\n",
    "\n",
    "**시나리오 1: 다양한 모델 비교 (자동 관리)**\n",
    "```python\n",
    "# EfficientNet B0 실험\n",
    "CFG.model_name = 'efficientnet_b0'  # ← 이것만 바꾸면 됨!\n",
    "# → efficientnet_b0_001, efficientnet_b0_002 ...\n",
    "\n",
    "# EfficientNet B3 실험\n",
    "CFG.model_name = 'efficientnet_b3'  # ← 이것만 바꾸면 됨!\n",
    "# → efficientnet_b3_001, efficientnet_b3_002 ...\n",
    "\n",
    "# ResNet50 실험\n",
    "CFG.model_name = 'resnet50'  # ← 이것만 바꾸면 됨!\n",
    "# → resnet50_001, resnet50_002 ...\n",
    "```\n",
    "\n",
    "**시나리오 2: 전략별 실험 (커스텀 prefix)**\n",
    "```python\n",
    "# 기본 베이스라인\n",
    "CFG.experiment_prefix = 'baseline'\n",
    "# → baseline_001, baseline_002 ...\n",
    "\n",
    "# 강한 데이터 증강 실험\n",
    "CFG.experiment_prefix = 'strong_augment'\n",
    "# → strong_augment_001, strong_augment_002 ...\n",
    "\n",
    "# 앙상블 실험\n",
    "CFG.experiment_prefix = 'ensemble'\n",
    "# → ensemble_001, ensemble_002 ...\n",
    "```\n",
    "\n",
    "**시나리오 3: 같은 모델로 다양한 하이퍼파라미터 실험**\n",
    "```python\n",
    "# EfficientNet B0로 여러 학습률 실험\n",
    "CFG.model_name = 'efficientnet_b0'\n",
    "CFG.experiment_prefix = 'effb0_lr_tuning'  # 커스텀 prefix 사용\n",
    "\n",
    "CFG.learning_rate = 1e-4\n",
    "# → effb0_lr_tuning_001\n",
    "\n",
    "CFG.learning_rate = 1e-5\n",
    "# → effb0_lr_tuning_002\n",
    "\n",
    "CFG.learning_rate = 5e-5\n",
    "# → effb0_lr_tuning_003\n",
    "```\n",
    "\n",
    "#### 📊 실행 예시\n",
    "\n",
    "**첫 번째 실험 (EfficientNet B0):**\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b0'\n",
    "```\n",
    "출력:\n",
    "```\n",
    "============================================================\n",
    "WandB Run initialized: efficientnet_b0_001\n",
    "WandB URL: https://wandb.ai/username/document-classification/runs/xxx\n",
    "============================================================\n",
    "```\n",
    "\n",
    "**같은 모델로 두 번째 실험:**\n",
    "```\n",
    "============================================================\n",
    "WandB Run initialized: efficientnet_b0_002\n",
    "WandB URL: https://wandb.ai/username/document-classification/runs/yyy\n",
    "============================================================\n",
    "```\n",
    "\n",
    "**모델 변경 후 실험:**\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b3'\n",
    "```\n",
    "출력:\n",
    "```\n",
    "============================================================\n",
    "WandB Run initialized: efficientnet_b3_001\n",
    "WandB URL: https://wandb.ai/username/document-classification/runs/zzz\n",
    "============================================================\n",
    "```\n",
    "\n",
    "#### ⚙️ 작동 원리\n",
    "1. `CFG.experiment_prefix = None`이면 → `CFG.model_name`을 자동으로 사용\n",
    "2. `CFG.experiment_name = None`이면 → 자동 번호 부여 모드 활성화\n",
    "3. WandB API를 통해 프로젝트의 기존 실험들을 확인\n",
    "4. prefix로 시작하는 실험 중 가장 큰 번호 찾기\n",
    "5. 가장 큰 번호 + 1로 새 실험명 생성\n",
    "6. 해당 prefix의 첫 실험이면 001부터 시작\n",
    "\n",
    "#### 🎯 실전 팁\n",
    "- **초간단 사용**: `CFG.model_name`만 바꾸면 모든 게 자동입니다! ⭐\n",
    "- **모델 비교**: 각 모델별로 자동으로 그룹화되어 비교가 쉽습니다\n",
    "- **전략 비교**: 같은 전략의 실험들을 묶고 싶으면 `experiment_prefix`를 직접 지정하세요\n",
    "- **WandB 필터링**: WandB 대시보드에서 prefix별로 필터링하면 비교가 쉽습니다\n",
    "- **재실행**: 코랩 런타임이 끊겨도 번호는 계속 이어집니다 (WandB 서버에 저장되므로)\n",
    "\n",
    "#### 📋 빠른 참조 테이블\n",
    "\n",
    "| 상황 | 설정 방법 | 결과 예시 |\n",
    "|------|-----------|-----------|\n",
    "| **기본 사용 (모델명 자동)** | `CFG.model_name = 'efficientnet_b0'`만 설정 | `efficientnet_b0_001` |\n",
    "| **다른 모델로 변경** | `CFG.model_name = 'resnet50'`으로 변경 | `resnet50_001` |\n",
    "| 전략별 그룹화 | `CFG.experiment_prefix = 'baseline'` | `baseline_001` |\n",
    "| 수동 이름 지정 | `CFG.experiment_name = 'my_best_model'` | `my_best_model` |\n",
    "| 하이퍼파라미터 튜닝 | `CFG.experiment_prefix = 'lr_tuning'` | `lr_tuning_001` |\n",
    "\n",
    "#### 🚀 실전 워크플로우 예시\n",
    "\n",
    "**1일차: EfficientNet B0 실험**\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b0'\n",
    "# 학습 실행 → efficientnet_b0_001\n",
    "```\n",
    "\n",
    "**2일차: 하이퍼파라미터 조정**\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b0'  # 그대로\n",
    "CFG.learning_rate = 5e-5  # 변경\n",
    "# 학습 실행 → efficientnet_b0_002\n",
    "```\n",
    "\n",
    "**3일차: 더 큰 모델로 실험**\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b3'  # 모델만 변경!\n",
    "# 학습 실행 → efficientnet_b3_001\n",
    "```\n",
    "\n",
    "**4일차: ResNet도 시도**\n",
    "```python\n",
    "CFG.model_name = 'resnet50'  # 모델만 변경!\n",
    "# 학습 실행 → resnet50_001\n",
    "```\n",
    "\n",
    "**5일차: 최고 성능 모델 재학습**\n",
    "```python\n",
    "CFG.model_name = 'efficientnet_b3'\n",
    "CFG.experiment_name = 'final_submission'  # 수동 지정\n",
    "# 학습 실행 → final_submission\n",
    "```\n",
    "\n",
    "### 6. WandB 일반 사용법\n",
    "1. **첫 실행시**: `wandb.login()` 실행 후 https://wandb.ai/authorize 에서 API 키 복사/붙여넣기\n",
    "2. **실험 추적**: 학습 중 WandB 대시보드에서 실시간 모니터링\n",
    "3. **결과 확인**: 학습 완료 후 WandB URL에서 모든 메트릭과 차트 확인\n",
    "4. **실험 비교**: 여러 실험을 선택해서 성능 비교 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}